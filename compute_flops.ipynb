{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcb5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTHS = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, \n",
    "           2048, 4096, 8192, 16384, 32768, 65536, 131072, 262144, 524288, 1048576,\n",
    "              2097152, 4194304, 8388608, 16777216]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424920c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_flops_est(model, batch_size=1, sequence_length=1):\n",
    "    \"\"\"\n",
    "    Compte les FLOPs (Floating Point Operations) pour le modèle Echo State Transformer (nouvelle implémentation).\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Instance du modèle EST\n",
    "    - batch_size: Taille du batch\n",
    "    - sequence_length: Longueur de la séquence\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionnaire détaillé des FLOPs par composant\n",
    "    - int: Total des FLOPs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Paramètres du modèle\n",
    "    B = batch_size\n",
    "    T = sequence_length\n",
    "    L = model.num_layers  # Nombre de couches\n",
    "    M = model.memory_units  # Nombre d'unités mémoire\n",
    "    R = model.memory_dim  # Dimension mémoire\n",
    "    D = model.attention_dim  # Dimension attention\n",
    "    I = model.enc_in  # Dimension d'entrée\n",
    "    \n",
    "    # Paramètres de sortie selon la tâche\n",
    "    if hasattr(model.projection, 'out_features'):\n",
    "        O = model.projection.out_features\n",
    "    else:\n",
    "        O = D  # Par défaut\n",
    "    \n",
    "    flops_breakdown = {}\n",
    "    \n",
    "    # ==================== EMBEDDING LAYER ====================\n",
    "    \n",
    "    # Input embedding (DataEmbedding)\n",
    "    # Approximation: principalement la projection linéaire value_embedding\n",
    "    flops_breakdown['input_embedding'] = B * T * I * D\n",
    "    \n",
    "    # ==================== EST LAYER LEVEL (répété L fois pour T timesteps) ====================\n",
    "    \n",
    "    layer_flops = {}\n",
    "    \n",
    "    # ==================== MEMORY FORWARD ====================\n",
    "    \n",
    "    memory_flops = {}\n",
    "    \n",
    "    # Adaptive Leak Rate computation\n",
    "    # X @ adaptive_lr: [B, M, 1, D] @ [M, D, 1] -> [B, M, 1, 1]\n",
    "    memory_flops['adaptive_lr_mm'] = B * M * D * 1 * T\n",
    "    \n",
    "    # Softmax sur adaptive_lr (division par temperature + softmax)\n",
    "    memory_flops['adaptive_lr_softmax'] = B * M * 1 * 1 * 3 * T  # exp + sum + div\n",
    "    \n",
    "    # Feed computation (sparse matrix multiplication)\n",
    "    # Estimation basée sur la connectivité fixe\n",
    "    input_connectivity = model.est_layers[0].memory.input_connectivity\n",
    "    feed_connections = int(input_connectivity * R)  # Nombre de connexions par colonne\n",
    "    # Sparse MM: [B, M, 1, D] avec [M, D, R] -> [B, M, 1, R]\n",
    "    memory_flops['feed_sparse_mm'] = B * M * D * feed_connections * T\n",
    "    \n",
    "    # Echo computation (sparse matrix multiplication + bias)\n",
    "    res_connectivity = model.est_layers[0].memory.res_connectivity\n",
    "    echo_connections = int(res_connectivity * R)  # Nombre de connexions par colonne\n",
    "    # Sparse MM: [B, M, 1, R] avec [M, R, R] -> [B, M, 1, R]\n",
    "    memory_flops['echo_sparse_mm'] = B * M * R * echo_connections * T\n",
    "    # Addition du biais: [B, M, 1, R] + [M, 1, R]\n",
    "    memory_flops['echo_bias_add'] = B * M * 1 * R * T\n",
    "    \n",
    "    # State update computation\n",
    "    # (1 - lr) * state: [B, M, 1, 1] * [B, M, 1, R]\n",
    "    memory_flops['state_update_mul1'] = B * M * 1 * R * T\n",
    "    # lr * tanh(feed + echo): addition + tanh + multiplication\n",
    "    memory_flops['feed_echo_add'] = B * M * 1 * R * T  # feed + echo\n",
    "    memory_flops['tanh'] = B * M * 1 * R * T  # tanh\n",
    "    memory_flops['state_update_mul2'] = B * M * 1 * R * T  # lr * tanh(...)\n",
    "    # Final addition: ((1-lr)*state) + lr*tanh(...)\n",
    "    memory_flops['state_update_final_add'] = B * M * 1 * R * T\n",
    "    \n",
    "    # Output computation: new_state @ Wout\n",
    "    # [B, M, 1, R] @ [M, R, D] -> [B, M, 1, D]\n",
    "    memory_flops['output_mm'] = B * M * R * D * T\n",
    "    \n",
    "    # ==================== ATTENTION MECHANISMS ====================\n",
    "    \n",
    "    attention_flops = {}\n",
    "    \n",
    "    # Attention on previous states\n",
    "    # Q = emb @ Wq: [B, 1, 1, D] @ [M, D, D] -> [B, M, 1, D]\n",
    "    attention_flops['Q_computation'] = B * M * D * D * T\n",
    "    \n",
    "    # K = Sout @ Wk: [B, M, M, D] @ [M, D, D] -> [B, M, M, D]\n",
    "    attention_flops['K_computation'] = B * M * M * D * D * T\n",
    "    \n",
    "    # V = Sout @ Wv: [B, M, M, D] @ [M, D, D] -> [B, M, M, D]\n",
    "    attention_flops['V_computation'] = B * M * M * D * D * T\n",
    "    \n",
    "    # Scaled dot product attention: Q @ K^T\n",
    "    # [B, M, 1, D] @ [B, M, D, M] -> [B, M, 1, M]\n",
    "    attention_flops['QKT_mm'] = B * M * 1 * D * M * T\n",
    "    \n",
    "    # Scale + Softmax\n",
    "    attention_flops['scale_attention'] = B * M * 1 * M * T\n",
    "    attention_flops['attention_softmax'] = B * M * 1 * M * 3 * T  # exp + sum + div\n",
    "    \n",
    "    # Attention weights @ V: [B, M, 1, M] @ [B, M, M, D] -> [B, M, 1, D]\n",
    "    attention_flops['attention_V_mm'] = B * M * 1 * M * D * T\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # Residual connection + norm1\n",
    "    attention_flops['residual_add1'] = B * M * D * T\n",
    "    # RMS Norm: sqrt(mean(x^2)) et division (approximation: 3 ops par élément)\n",
    "    attention_flops['norm1'] = B * M * D * 3 * T\n",
    "    \n",
    "    # Self-attention on current state\n",
    "    # SQ, SK, SV computations: [B, M, D] @ [D, D] -> [B, M, D] (x3)\n",
    "    attention_flops['SQ_computation'] = B * M * D * D * T\n",
    "    attention_flops['SK_computation'] = B * M * D * D * T\n",
    "    attention_flops['SV_computation'] = B * M * D * D * T\n",
    "    \n",
    "    # Self-attention: SQ @ SK^T: [B, M, D] @ [B, D, M] -> [B, M, M]\n",
    "    attention_flops['self_QKT_mm'] = B * M * D * M * T\n",
    "    \n",
    "    # Scale + Softmax\n",
    "    attention_flops['self_scale_attention'] = B * M * M * T\n",
    "    attention_flops['self_attention_softmax'] = B * M * M * 3 * T\n",
    "    \n",
    "    # Self-attention weights @ SV: [B, M, M] @ [B, M, D] -> [B, M, D]\n",
    "    attention_flops['self_attention_V_mm'] = B * M * M * D * T\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # Residual connection + norm2\n",
    "    attention_flops['residual_add2'] = B * M * D * T\n",
    "    attention_flops['norm2'] = B * M * D * 3 * T\n",
    "    \n",
    "    # ==================== FEED FORWARD ====================\n",
    "    \n",
    "    ff_flops = {}\n",
    "    \n",
    "    # Reduction: [B, M*D] @ [M*D, D] -> [B, D]\n",
    "    ff_flops['reduction_mm'] = B * (M * D) * D * T\n",
    "    \n",
    "    # Feed forward in: [B, D] @ [D, 4*D] -> [B, 4*D]\n",
    "    ff_flops['ff_in_mm'] = B * D * (4 * D) * T\n",
    "    \n",
    "    # GELU activation (approximation: 4 ops par élément)\n",
    "    ff_flops['gelu'] = B * (4 * D) * 4 * T\n",
    "    \n",
    "    # Feed forward out: [B, 4*D] @ [4*D, D] -> [B, D]\n",
    "    ff_flops['ff_out_mm'] = B * (4 * D) * D * T\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # Residual connection + norm3\n",
    "    ff_flops['residual_add3'] = B * D * T\n",
    "    ff_flops['norm3'] = B * D * 3 * T\n",
    "    \n",
    "    # ==================== ASSEMBLY LAYER FLOPS ====================\n",
    "    \n",
    "    # Somme des FLOPs pour une couche EST\n",
    "    layer_total = (sum(memory_flops.values()) + \n",
    "                  sum(attention_flops.values()) + \n",
    "                  sum(ff_flops.values()))\n",
    "    \n",
    "    layer_flops['memory'] = memory_flops\n",
    "    layer_flops['attention'] = attention_flops\n",
    "    layer_flops['feed_forward'] = ff_flops\n",
    "    layer_flops['total_per_layer'] = layer_total\n",
    "    \n",
    "    # ==================== OUTPUT PROJECTION ====================\n",
    "    \n",
    "    # Classification: flatten + projection\n",
    "    if model.task_name == 'classification':\n",
    "        # Flatten: [B, T, D] -> [B, T*D] (pas de FLOPs)\n",
    "        # Projection: [B, T*D] @ [T*D, O] -> [B, O]\n",
    "        flops_breakdown['output_projection'] = B * (T * D) * O\n",
    "        # GELU + Dropout (pas de FLOPs pour dropout)\n",
    "        flops_breakdown['output_activation'] = B * (T * D) * 2  # GELU approximation\n",
    "    else:\n",
    "        # Direct projection: [B, T, D] @ [D, O] -> [B, T, O]\n",
    "        flops_breakdown['output_projection'] = B * T * D * O\n",
    "        flops_breakdown['output_activation'] = 0\n",
    "    \n",
    "    # ==================== NORMALIZATION (si applicable) ====================\n",
    "    \n",
    "    normalization_flops = 0\n",
    "    if model.task_name in ['long_term_forecast', 'short_term_forecast']:\n",
    "        # Mean computation: B * T * D operations\n",
    "        normalization_flops += B * T * D\n",
    "        # Std computation: B * T * D operations (var + sqrt)\n",
    "        normalization_flops += B * T * D * 2\n",
    "        # Normalization: B * T * D operations (subtract + divide)\n",
    "        normalization_flops += B * T * D * 2\n",
    "        # Denormalization: B * T * D operations (multiply + add)\n",
    "        normalization_flops += B * T * D * 2\n",
    "    \n",
    "    flops_breakdown['normalization'] = normalization_flops\n",
    "    \n",
    "    # ==================== TOTAL CALCULATION ====================\n",
    "    \n",
    "    flops_breakdown['layers'] = layer_flops\n",
    "    flops_breakdown['total_layers'] = layer_total * L  # Multiplier par le nombre de couches\n",
    "    \n",
    "    total_flops = (flops_breakdown['input_embedding'] + \n",
    "                  flops_breakdown['total_layers'] + \n",
    "                  flops_breakdown['output_projection'] +\n",
    "                  flops_breakdown['output_activation'] +\n",
    "                  flops_breakdown['normalization'])\n",
    "    \n",
    "    flops_breakdown['total'] = total_flops\n",
    "    \n",
    "    return flops_breakdown, total_flops\n",
    "\n",
    "def print_flops_breakdown_est(flops_breakdown, total_flops):\n",
    "    \"\"\"\n",
    "    Affiche un résumé détaillé des FLOPs pour EST v2.\n",
    "    \n",
    "    Parameters:\n",
    "    - flops_breakdown: Dictionnaire des FLOPs par composant\n",
    "    - total_flops: Total des FLOPs\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ECHO STATE TRANSFORMER V2 - FLOPs BREAKDOWN\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"Input Embedding: {flops_breakdown['input_embedding']:,} FLOPs\")\n",
    "    print(f\"Output Projection: {flops_breakdown['output_projection']:,} FLOPs\")\n",
    "    if flops_breakdown['output_activation'] > 0:\n",
    "        print(f\"Output Activation: {flops_breakdown['output_activation']:,} FLOPs\")\n",
    "    if flops_breakdown['normalization'] > 0:\n",
    "        print(f\"Normalization: {flops_breakdown['normalization']:,} FLOPs\")\n",
    "    \n",
    "    print(f\"\\nPer Layer FLOPs: {flops_breakdown['layers']['total_per_layer']:,}\")\n",
    "    print(f\"Total Layers FLOPs: {flops_breakdown['total_layers']:,}\")\n",
    "    \n",
    "    print(f\"\\n--- Layer Breakdown ---\")\n",
    "    memory_total = sum(flops_breakdown['layers']['memory'].values())\n",
    "    attention_total = sum(flops_breakdown['layers']['attention'].values())\n",
    "    ff_total = sum(flops_breakdown['layers']['feed_forward'].values())\n",
    "    \n",
    "    layer_total = flops_breakdown['layers']['total_per_layer']\n",
    "    print(f\"Memory Operations: {memory_total:,} FLOPs ({memory_total/layer_total*100:.1f}%)\")\n",
    "    print(f\"Attention Mechanisms: {attention_total:,} FLOPs ({attention_total/layer_total*100:.1f}%)\")\n",
    "    print(f\"Feed Forward: {ff_total:,} FLOPs ({ff_total/layer_total*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n--- Detailed Memory Breakdown ---\")\n",
    "    for component, flops in flops_breakdown['layers']['memory'].items():\n",
    "        print(f\"  {component}: {flops:,} FLOPs\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"TOTAL FLOPs: {total_flops:,}\")\n",
    "    print(f\"TOTAL GFLOPs: {total_flops / 1e9:.3f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "\n",
    "\n",
    "# Test de la nouvelle fonction count_flops_est_v2 avec le modèle EST\n",
    "from models.EST import Model as EST\n",
    "\n",
    "# Configuration du modèle EST (adaptée à votre nouvelle implémentation)\n",
    "configs_est = type('Config', (), {\n",
    "    'task_name': 'anomaly_detection',  \n",
    "    'pred_len': 10, \n",
    "    'seq_len': 10,\n",
    "    'num_layers': 1,  # Moins de couches\n",
    "    'd_model': 192,   # Dimension plus petite\n",
    "    'dropout': 0.0,\n",
    "    'memory_units': 4,  # Moins d'unités\n",
    "    'memory_dim': 64,   # Dimension plus petite\n",
    "    'memory_connectivity': 0.125,\n",
    "    'enc_in': 10,\n",
    "    'c_out': 10,\n",
    "    'num_class': 10,\n",
    "    'embed': 'timeF',\n",
    "    'freq': 'h'\n",
    "})()\n",
    "\n",
    "# Créer le modèle EST\n",
    "model_est = EST(configs_est)\n",
    "print(\"Model parameters:\", sum(p.numel() for p in model_est.parameters()))\n",
    "\n",
    "# Test avec un exemple\n",
    "batch_size = 32\n",
    "sequence_length = 96\n",
    "flops_breakdown, total_flops = count_flops_est(model_est, batch_size=batch_size, sequence_length=sequence_length)\n",
    "\n",
    "# Afficher les résultats détaillés\n",
    "print_flops_breakdown_est(flops_breakdown, total_flops)\n",
    "\n",
    "# Test avec différentes longueurs de séquence\n",
    "print(f\"\\n=== TEST AVEC DIFFÉRENTES LONGUEURS DE SÉQUENCE ===\")\n",
    "flops_est = []\n",
    "\n",
    "for seq_len in SEQ_LENGTHS:\n",
    "    flops_breakdown, total_flops = count_flops_est(model_est, batch_size=10, sequence_length=seq_len)\n",
    "    print(f\"Sequence Length: {seq_len:4d}, Total FLOPs: {total_flops:12,}, GFLOPs: {total_flops/1e9:8.3f}\")\n",
    "    flops_est.append(total_flops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3166e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_flops_transformer_vanilla(model, batch_size=1, sequence_length=1, configs={}):\n",
    "    \"\"\"\n",
    "    Compte les FLOPs (Floating Point Operations) pour le modèle Transformer Vanilla.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Instance du modèle Transformer\n",
    "    - batch_size: Taille du batch\n",
    "    - sequence_length: Longueur de la séquence\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionnaire détaillé des FLOPs par composant\n",
    "    - int: Total des FLOPs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Paramètres du modèle\n",
    "    B = batch_size\n",
    "    S = sequence_length  # Sequence length\n",
    "\n",
    "    # Récupérer les paramètres depuis le modèle\n",
    "    # Encoder parameters\n",
    "    encoder_layers = configs.get('e_layers')\n",
    "    d_model = configs.get('d_model')\n",
    "    n_heads = configs.get('n_heads')  # Valeur par défaut si non spécifié\n",
    "    \n",
    "    # Pour d_ff, on regarde les conv layers (conv1 et conv2)\n",
    "    if encoder_layers > 0:\n",
    "        d_ff = configs.get('d_ff')\n",
    "    else:\n",
    "        d_ff = d_model * 4\n",
    "\n",
    "    I = configs.get('enc_in')  # Input features\n",
    "    \n",
    "    # Output dimension selon la tâche\n",
    "    if model.task_name == 'classification':\n",
    "        O = model.projection.out_features\n",
    "    elif hasattr(model, 'projection'):\n",
    "        O = model.projection.out_features\n",
    "    elif model.task_name in ['long_term_forecast', 'short_term_forecast'] and hasattr(model, 'decoder'):\n",
    "        O = model.decoder.projection.out_features\n",
    "    else:\n",
    "        O = d_model\n",
    "    \n",
    "    # Dimension par tête d'attention\n",
    "    head_dim = d_model // n_heads\n",
    "    \n",
    "    flops_breakdown = {}\n",
    "    \n",
    "    # ==================== INPUT EMBEDDING ====================\n",
    "    \n",
    "    # Input embedding: Conv1d tokenization\n",
    "    # Conv1d: [B, I, S] -> [B, d_model, S] avec kernel_size=3, padding=1\n",
    "    conv_kernel_size = model.enc_embedding.value_embedding.tokenConv.kernel_size[0]\n",
    "    flops_breakdown['input_embedding'] = B * S * I * d_model * conv_kernel_size\n",
    "    \n",
    "    # Positional embedding (pas de FLOPs, juste addition)\n",
    "    # Temporal embedding: Linear layer [4 -> d_model]\n",
    "    temporal_features = model.enc_embedding.temporal_embedding.embed.in_features\n",
    "    flops_breakdown['positional_temporal_embedding'] = B * S * temporal_features * d_model\n",
    "    \n",
    "    # ==================== ENCODER LAYERS ====================\n",
    "    \n",
    "    encoder_layer_flops = {}\n",
    "    \n",
    "    # ==================== MULTI-HEAD ATTENTION ====================\n",
    "    \n",
    "    attention_flops = {}\n",
    "    \n",
    "    # Query, Key, Value projections\n",
    "    # Input: [B, S, d_model] -> Output: [B, S, d_model] (pour chacune des 3 projections)\n",
    "    attention_flops['Q_projection'] = B * S * d_model * d_model\n",
    "    attention_flops['K_projection'] = B * S * d_model * d_model\n",
    "    attention_flops['V_projection'] = B * S * d_model * d_model\n",
    "    \n",
    "    # Reshape pour multi-head: [B, S, d_model] -> [B, n_heads, S, head_dim]\n",
    "    # Pas de FLOPs, juste un reshape\n",
    "    \n",
    "    # Attention scores: Q @ K^T\n",
    "    # Q: [B, n_heads, S, head_dim], K^T: [B, n_heads, head_dim, S] -> [B, n_heads, S, S]\n",
    "    attention_flops['attention_scores'] = B * n_heads * S * head_dim * S\n",
    "    \n",
    "    # Scale by sqrt(head_dim)\n",
    "    attention_flops['scale_attention'] = B * n_heads * S * S\n",
    "    \n",
    "    # Softmax sur la dimension des clés (S)\n",
    "    # Approximation: exp + sum + divide = 3 opérations par élément\n",
    "    attention_flops['attention_softmax'] = B * n_heads * S * S * 3\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # Attention weights @ V: [B, n_heads, S, S] @ [B, n_heads, S, head_dim] -> [B, n_heads, S, head_dim]\n",
    "    attention_flops['attention_values'] = B * n_heads * S * S * head_dim\n",
    "    \n",
    "    # Concatenate heads: [B, n_heads, S, head_dim] -> [B, S, d_model]\n",
    "    # Pas de FLOPs, juste un reshape\n",
    "    \n",
    "    # Output projection: [B, S, d_model] @ [d_model, d_model] -> [B, S, d_model]\n",
    "    attention_flops['output_projection'] = B * S * d_model * d_model\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # Residual connection + LayerNorm1\n",
    "    attention_flops['residual_add'] = B * S * d_model\n",
    "    attention_flops['layer_norm1'] = B * S * d_model * 3  # mean, var, normalize\n",
    "    \n",
    "    # ==================== FEED FORWARD NETWORK (Conv-based) ====================\n",
    "    \n",
    "    feedforward_flops = {}\n",
    "    \n",
    "    # Conv1: [B, d_model, S] -> [B, d_ff, S] avec kernel_size=1\n",
    "    feedforward_flops['conv1'] = B * S * d_model * d_ff\n",
    "    \n",
    "    # Activation (GELU)\n",
    "    # Approximation: 2 opérations par élément pour GELU\n",
    "    feedforward_flops['activation'] = B * S * d_ff * 2\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # Conv2: [B, d_ff, S] -> [B, d_model, S] avec kernel_size=1\n",
    "    feedforward_flops['conv2'] = B * S * d_ff * d_model\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # Residual connection + LayerNorm2\n",
    "    feedforward_flops['residual_add'] = B * S * d_model\n",
    "    feedforward_flops['layer_norm2'] = B * S * d_model * 3\n",
    "    \n",
    "    # ==================== ASSEMBLY ENCODER LAYER FLOPS ====================\n",
    "    \n",
    "    # Somme des FLOPs pour une couche d'encodeur\n",
    "    encoder_layer_total = sum(attention_flops.values()) + sum(feedforward_flops.values())\n",
    "    \n",
    "    encoder_layer_flops['attention'] = attention_flops\n",
    "    encoder_layer_flops['feedforward'] = feedforward_flops\n",
    "    encoder_layer_flops['total_per_layer'] = encoder_layer_total\n",
    "    \n",
    "    # ==================== LAYER NORM FINALE ENCODER ====================\n",
    "    \n",
    "    encoder_norm_flops = 0\n",
    "    if hasattr(model.encoder, 'norm') and model.encoder.norm is not None:\n",
    "        encoder_norm_flops = B * S * d_model * 3\n",
    "    \n",
    "    # ==================== DECODER (si applicable) ====================\n",
    "    \n",
    "    decoder_flops = 0\n",
    "    decoder_layer_flops = {}\n",
    "    \n",
    "    if model.task_name in ['long_term_forecast', 'short_term_forecast'] and hasattr(model, 'decoder'):\n",
    "        # Paramètres decoder\n",
    "        decoder_layers = len(model.decoder.layers) if hasattr(model.decoder, 'layers') else 0\n",
    "        \n",
    "        if decoder_layers > 0:\n",
    "            # Dec embedding (similaire à enc_embedding)\n",
    "            dec_embedding_flops = B * S * I * d_model * conv_kernel_size + B * S * temporal_features * d_model\n",
    "            \n",
    "            # Pour chaque couche decoder (structure similaire à l'encoder)\n",
    "            decoder_attention_flops = {}\n",
    "            \n",
    "            # Self-attention (avec masque causal)\n",
    "            decoder_attention_flops['self_Q_proj'] = B * S * d_model * d_model\n",
    "            decoder_attention_flops['self_K_proj'] = B * S * d_model * d_model\n",
    "            decoder_attention_flops['self_V_proj'] = B * S * d_model * d_model\n",
    "            decoder_attention_flops['self_attention_scores'] = B * n_heads * S * head_dim * S\n",
    "            decoder_attention_flops['self_scale_attention'] = B * n_heads * S * S\n",
    "            decoder_attention_flops['self_attention_softmax'] = B * n_heads * S * S * 3\n",
    "            decoder_attention_flops['self_attention_values'] = B * n_heads * S * S * head_dim\n",
    "            decoder_attention_flops['self_output_proj'] = B * S * d_model * d_model\n",
    "            decoder_attention_flops['self_residual'] = B * S * d_model\n",
    "            decoder_attention_flops['self_norm1'] = B * S * d_model * 3\n",
    "            \n",
    "            # Cross-attention (decoder vers encoder)\n",
    "            decoder_attention_flops['cross_Q_proj'] = B * S * d_model * d_model\n",
    "            decoder_attention_flops['cross_K_proj'] = B * S * d_model * d_model\n",
    "            decoder_attention_flops['cross_V_proj'] = B * S * d_model * d_model\n",
    "            decoder_attention_flops['cross_attention_scores'] = B * n_heads * S * head_dim * S\n",
    "            decoder_attention_flops['cross_scale_attention'] = B * n_heads * S * S\n",
    "            decoder_attention_flops['cross_attention_softmax'] = B * n_heads * S * S * 3\n",
    "            decoder_attention_flops['cross_attention_values'] = B * n_heads * S * S * head_dim\n",
    "            decoder_attention_flops['cross_output_proj'] = B * S * d_model * d_model\n",
    "            decoder_attention_flops['cross_residual'] = B * S * d_model\n",
    "            decoder_attention_flops['cross_norm2'] = B * S * d_model * 3\n",
    "            \n",
    "            # Feed forward decoder (Conv-based)\n",
    "            decoder_ff_flops = {}\n",
    "            decoder_ff_flops['conv1'] = B * S * d_model * d_ff\n",
    "            decoder_ff_flops['activation'] = B * S * d_ff * 2\n",
    "            decoder_ff_flops['conv2'] = B * S * d_ff * d_model\n",
    "            decoder_ff_flops['residual_add'] = B * S * d_model\n",
    "            decoder_ff_flops['layer_norm3'] = B * S * d_model * 3\n",
    "            \n",
    "            # Total par couche decoder\n",
    "            decoder_layer_total = sum(decoder_attention_flops.values()) + sum(decoder_ff_flops.values())\n",
    "            \n",
    "            decoder_layer_flops['attention'] = decoder_attention_flops\n",
    "            decoder_layer_flops['feedforward'] = decoder_ff_flops\n",
    "            decoder_layer_flops['total_per_layer'] = decoder_layer_total\n",
    "            \n",
    "            # Total decoder\n",
    "            decoder_flops = (dec_embedding_flops + \n",
    "                            decoder_layer_total * decoder_layers + \n",
    "                            B * S * d_model * 3)  # Norm finale\n",
    "            \n",
    "            # Projection finale\n",
    "            decoder_projection_flops = B * S * d_model * O\n",
    "            \n",
    "            flops_breakdown['dec_embedding'] = dec_embedding_flops\n",
    "            flops_breakdown['decoder_layers'] = decoder_layer_total * decoder_layers\n",
    "            flops_breakdown['decoder_projection'] = decoder_projection_flops\n",
    "    \n",
    "    # ==================== OUTPUT PROJECTION ====================\n",
    "    \n",
    "    output_flops = 0\n",
    "    \n",
    "    if model.task_name == 'classification':\n",
    "        # Flatten + GELU + Dropout + Projection\n",
    "        # output = output.reshape(B, -1): pas de FLOPs\n",
    "        # GELU: [B, S * d_model]\n",
    "        gelu_flops = B * S * d_model * 2\n",
    "        # Projection: [B, S * d_model] @ [S * d_model, num_classes] -> [B, num_classes]\n",
    "        projection_flops = B * (S * d_model) * O\n",
    "        \n",
    "        output_flops = gelu_flops + projection_flops\n",
    "        \n",
    "        flops_breakdown['output_activation'] = gelu_flops\n",
    "        flops_breakdown['output_projection'] = projection_flops\n",
    "        \n",
    "    elif model.task_name in ['imputation', 'anomaly_detection']:\n",
    "        # Direct projection: [B, S, d_model] @ [d_model, O] -> [B, S, O]\n",
    "        output_flops = B * S * d_model * O\n",
    "        flops_breakdown['output_projection'] = output_flops\n",
    "    \n",
    "    # ==================== TOTAL CALCULATION ====================\n",
    "    \n",
    "    flops_breakdown['input_embedding'] = flops_breakdown['input_embedding']\n",
    "    flops_breakdown['positional_temporal_embedding'] = flops_breakdown['positional_temporal_embedding']\n",
    "    flops_breakdown['encoder_layers'] = encoder_layer_flops\n",
    "    flops_breakdown['total_encoder_layers'] = encoder_layer_total * encoder_layers\n",
    "    flops_breakdown['encoder_norm'] = encoder_norm_flops\n",
    "    \n",
    "    if decoder_flops > 0:\n",
    "        flops_breakdown['decoder_layers_detail'] = decoder_layer_flops\n",
    "        flops_breakdown['total_decoder'] = decoder_flops\n",
    "    \n",
    "    total_flops = (flops_breakdown['input_embedding'] + \n",
    "                  flops_breakdown['positional_temporal_embedding'] +\n",
    "                  flops_breakdown['total_encoder_layers'] + \n",
    "                  flops_breakdown['encoder_norm'] +\n",
    "                  decoder_flops +\n",
    "                  output_flops)\n",
    "    \n",
    "    flops_breakdown['total'] = total_flops\n",
    "    \n",
    "    return flops_breakdown, total_flops\n",
    "\n",
    "def print_flops_breakdown_transformer_vanilla(flops_breakdown, total_flops):\n",
    "    \"\"\"\n",
    "    Affiche un résumé détaillé des FLOPs pour le Transformer Vanilla.\n",
    "    \n",
    "    Parameters:\n",
    "    - flops_breakdown: Dictionnaire des FLOPs par composant\n",
    "    - total_flops: Total des FLOPs\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(f\"TRANSFORMER VANILLA - FLOPs BREAKDOWN\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"Input Embedding: {flops_breakdown['input_embedding']:,} FLOPs\")\n",
    "    print(f\"Positional/Temporal Embedding: {flops_breakdown['positional_temporal_embedding']:,} FLOPs\")\n",
    "    print(f\"Encoder Norm: {flops_breakdown['encoder_norm']:,} FLOPs\")\n",
    "    \n",
    "    if 'output_projection' in flops_breakdown:\n",
    "        print(f\"Output Projection: {flops_breakdown['output_projection']:,} FLOPs\")\n",
    "    if 'output_activation' in flops_breakdown:\n",
    "        print(f\"Output Activation: {flops_breakdown['output_activation']:,} FLOPs\")\n",
    "    \n",
    "    print(f\"\\n=== ENCODER ===\")\n",
    "    print(f\"Per Encoder Layer FLOPs: {flops_breakdown['encoder_layers']['total_per_layer']:,}\")\n",
    "    print(f\"Total Encoder Layers FLOPs: {flops_breakdown['total_encoder_layers']:,}\")\n",
    "    \n",
    "    print(f\"\\n--- Encoder Layer Breakdown ---\")\n",
    "    encoder_attention_total = sum(flops_breakdown['encoder_layers']['attention'].values())\n",
    "    encoder_ff_total = sum(flops_breakdown['encoder_layers']['feedforward'].values())\n",
    "    encoder_layer_total = flops_breakdown['encoder_layers']['total_per_layer']\n",
    "    \n",
    "    print(f\"Multi-Head Attention: {encoder_attention_total:,} FLOPs ({encoder_attention_total/encoder_layer_total*100:.1f}%)\")\n",
    "    print(f\"Feed Forward Network (Conv): {encoder_ff_total:,} FLOPs ({encoder_ff_total/encoder_layer_total*100:.1f}%)\")\n",
    "    \n",
    "    # Decoder si présent\n",
    "    if 'total_decoder' in flops_breakdown:\n",
    "        print(f\"\\n=== DECODER ===\")\n",
    "        print(f\"Dec Embedding: {flops_breakdown['dec_embedding']:,} FLOPs\")\n",
    "        print(f\"Total Decoder Layers: {flops_breakdown['decoder_layers']:,} FLOPs\")\n",
    "        print(f\"Decoder Projection: {flops_breakdown['decoder_projection']:,} FLOPs\")\n",
    "        print(f\"Total Decoder: {flops_breakdown['total_decoder']:,} FLOPs\")\n",
    "        \n",
    "        if 'decoder_layers_detail' in flops_breakdown:\n",
    "            decoder_attention_total = sum(flops_breakdown['decoder_layers_detail']['attention'].values())\n",
    "            decoder_ff_total = sum(flops_breakdown['decoder_layers_detail']['feedforward'].values())\n",
    "            decoder_layer_total = flops_breakdown['decoder_layers_detail']['total_per_layer']\n",
    "            \n",
    "            print(f\"\\n--- Decoder Layer Breakdown ---\")\n",
    "            print(f\"Attention Mechanisms: {decoder_attention_total:,} FLOPs ({decoder_attention_total/decoder_layer_total*100:.1f}%)\")\n",
    "            print(f\"Feed Forward Network: {decoder_ff_total:,} FLOPs ({decoder_ff_total/decoder_layer_total*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n--- Detailed Encoder Attention Breakdown ---\")\n",
    "    for component, flops in flops_breakdown['encoder_layers']['attention'].items():\n",
    "        print(f\"  {component}: {flops:,} FLOPs\")\n",
    "    \n",
    "    print(f\"\\n--- Detailed Encoder Feed Forward Breakdown ---\")\n",
    "    for component, flops in flops_breakdown['encoder_layers']['feedforward'].items():\n",
    "        print(f\"  {component}: {flops:,} FLOPs\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"TOTAL FLOPs: {total_flops:,}\")\n",
    "    print(f\"TOTAL GFLOPs: {total_flops / 1e9:.3f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Test du modèle Transformer Vanilla\n",
    "from models.Transformer import Model as TransformerVanilla\n",
    "\n",
    "# Configuration pour le modèle Transformer\n",
    "conf_transformer = {\n",
    "    'task_name': 'anomaly_detection', \n",
    "    'pred_len': 1,\n",
    "    'seq_len': 10,\n",
    "    'enc_in': 10,        # Features d'entrée\n",
    "    'dec_in': 10,        # Features decoder (si applicable)\n",
    "    'c_out': 1,          # Features de sortie\n",
    "    'num_class': 10,     # Nombre de classes pour classification\n",
    "    'd_model': 256,       # Dimension du modèle\n",
    "    'n_heads': 8,        # Nombre de têtes d'attention\n",
    "    'd_ff': 512,         # Dimension feedforward\n",
    "    'e_layers': 2,       # Nombre de couches encoder\n",
    "    'd_layers': 1,       # Nombre de couches decoder\n",
    "    'factor': 5,         # Facteur pour attention\n",
    "    'dropout': 0.1,\n",
    "    'activation': 'gelu',\n",
    "    'embed': 'timeF',\n",
    "    'freq': 'h'\n",
    "}\n",
    "configs_transformer = type('Config', (), conf_transformer)()\n",
    "\n",
    "# Créer le modèle\n",
    "model_transformer = TransformerVanilla(configs_transformer)\n",
    "print(\"Model parameters:\", sum(p.numel() for p in model_transformer.parameters()))\n",
    "\n",
    "print(\"=== MODÈLE TRANSFORMER VANILLA CRÉÉ ===\")\n",
    "print(f\"Task: {model_transformer.task_name}\")\n",
    "if hasattr(model_transformer, 'decoder'):\n",
    "    print(f\"Decoder layers: {len(model_transformer.decoder.attn_layers)}\")\n",
    "\n",
    "# Test des FLOPs\n",
    "batch_size = 32\n",
    "sequence_length = 96\n",
    "\n",
    "flops_breakdown, total_flops = count_flops_transformer_vanilla(\n",
    "    model_transformer, batch_size=batch_size, sequence_length=sequence_length, configs=conf_transformer\n",
    ")\n",
    "\n",
    "# Afficher les résultats\n",
    "print_flops_breakdown_transformer_vanilla(flops_breakdown, total_flops)\n",
    "\n",
    "# Test avec différentes longueurs de séquence\n",
    "print(f\"\\n=== TEST AVEC DIFFÉRENTES LONGUEURS DE SÉQUENCE ===\")\n",
    "flops_transformer_vanilla = []\n",
    "\n",
    "for seq_len in SEQ_LENGTHS:\n",
    "    flops_breakdown, total_flops = count_flops_transformer_vanilla(\n",
    "        model_transformer, batch_size=10, sequence_length=seq_len, configs=conf_transformer\n",
    "    )\n",
    "    print(f\"Sequence Length: {seq_len:4d}, Total FLOPs: {total_flops:12,}, GFLOPs: {total_flops/1e9:8.3f}\")\n",
    "    flops_transformer_vanilla.append(total_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1637993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_flops_mamba(model, batch_size=1, sequence_length=1, configs={}):\n",
    "    \"\"\"\n",
    "    Compte les FLOPs (Floating Point Operations) pour le modèle Mamba.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Instance du modèle Mamba\n",
    "    - batch_size: Taille du batch\n",
    "    - sequence_length: Longueur de la séquence\n",
    "    - configs: Configuration du modèle (dict)\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionnaire détaillé des FLOPs par composant\n",
    "    - int: Total des FLOPs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Paramètres du modèle\n",
    "    B = batch_size\n",
    "    L = sequence_length  # Sequence length\n",
    "    \n",
    "    # Récupérer les paramètres depuis la configuration\n",
    "    d_model = configs.get('d_model')  # Dimension du modèle\n",
    "    expand = configs.get('expand', 2)  # Facteur d'expansion\n",
    "    d_inner = d_model * expand  # Dimension interne\n",
    "    dt_rank = math.ceil(d_model / 16)  # Rang pour delta (même calcul que dans le modèle)\n",
    "    n_layers = configs.get('e_layers')  # Nombre de couches\n",
    "    \n",
    "    # Input/Output dimensions\n",
    "    I = configs.get('enc_in')  # Input features\n",
    "    O = configs.get('c_out')  # Output features\n",
    "    \n",
    "    # Paramètres SSM\n",
    "    n = configs.get('d_ff')  # d_ff (dimension état)\n",
    "    d_conv = configs.get('d_conv')  # Taille kernel conv\n",
    "    \n",
    "    flops_breakdown = {}\n",
    "    \n",
    "    # ==================== INPUT EMBEDDING ====================\n",
    "    \n",
    "    # Input embedding: X @ W -> [B, L, I] @ [I, d_model] -> [B, L, d_model]\n",
    "    flops_breakdown['input_embedding'] = B * L * I * d_model\n",
    "    \n",
    "    # Positional/Temporal embedding (approximation)\n",
    "    flops_breakdown['positional_temporal_embedding'] = B * L * d_model * 2\n",
    "    \n",
    "    # ==================== MAMBA LAYERS ====================\n",
    "    \n",
    "    mamba_layer_flops = {}\n",
    "    \n",
    "    # ==================== RMS NORM (avant chaque couche) ====================\n",
    "    \n",
    "    norm_flops = {}\n",
    "    \n",
    "    # RMS Norm: sqrt(mean(x^2)) + scale\n",
    "    # Approximation: 3 opérations par élément (square, mean, sqrt+scale)\n",
    "    norm_flops['rms_norm'] = B * L * d_model * 3\n",
    "    \n",
    "    # ==================== MAMBA BLOCK ====================\n",
    "    \n",
    "    mamba_block_flops = {}\n",
    "    \n",
    "    # Input projection: [B, L, d_model] @ [d_model, 2*d_inner] -> [B, L, 2*d_inner]\n",
    "    mamba_block_flops['in_proj'] = B * L * d_model * (2 * d_inner)\n",
    "    \n",
    "    # Split en x et res (pas de FLOPs)\n",
    "    \n",
    "    # ==================== CONVOLUTION 1D ====================\n",
    "    \n",
    "    conv_flops = {}\n",
    "    \n",
    "    # Conv1d: [B, d_inner, L] avec kernel_size=d_conv, groups=d_inner\n",
    "    # Chaque groupe fait une convolution indépendante\n",
    "    conv_flops['conv1d'] = B * L * d_inner * d_conv\n",
    "    \n",
    "    # SiLU activation: approximation 2 opérations par élément\n",
    "    conv_flops['silu_activation'] = B * L * d_inner * 2\n",
    "    \n",
    "    # ==================== STATE SPACE MODEL (SSM) ====================\n",
    "    \n",
    "    ssm_flops = {}\n",
    "    \n",
    "    # x_proj: [B, L, d_inner] @ [d_inner, dt_rank + 2*n] -> [B, L, dt_rank + 2*n]\n",
    "    ssm_flops['x_proj'] = B * L * d_inner * (dt_rank + 2 * n)\n",
    "    \n",
    "    # Split en delta, B, C (pas de FLOPs)\n",
    "    \n",
    "    # dt_proj: [B, L, dt_rank] @ [dt_rank, d_inner] -> [B, L, d_inner]\n",
    "    ssm_flops['dt_proj'] = B * L * dt_rank * d_inner\n",
    "    \n",
    "    # Softplus sur delta: approximation 2 opérations par élément\n",
    "    ssm_flops['softplus_delta'] = B * L * d_inner * 2\n",
    "    \n",
    "    # Selective scan computation\n",
    "    # deltaA = exp(delta ⊗ A): [B, L, d_inner, n]\n",
    "    # Einsum: delta [B, L, d_inner] × A [d_inner, n] -> [B, L, d_inner, n]\n",
    "    ssm_flops['deltaA_einsum'] = B * L * d_inner * n\n",
    "    ssm_flops['deltaA_exp'] = B * L * d_inner * n\n",
    "    \n",
    "    # deltaB_u = delta ⊗ B ⊗ u: [B, L, d_inner, n]\n",
    "    # Triple einsum: delta [B, L, d_inner] × B [B, L, n] × u [B, L, d_inner]\n",
    "    ssm_flops['deltaB_u_einsum'] = B * L * d_inner * n * 2  # 2 multiplications\n",
    "    \n",
    "    # Selective scan séquentiel (pour L timesteps)\n",
    "    # Pour chaque timestep i:\n",
    "    #   x = deltaA[:, i] * x + deltaB_u[:, i]: [B, d_inner, n]\n",
    "    #   y = x ⊗ C[:, i]: [B, d_inner] \n",
    "    ssm_flops['selective_scan_update'] = L * B * d_inner * n * 2  # mult + add pour x\n",
    "    ssm_flops['selective_scan_output'] = L * B * d_inner * n      # einsum pour y\n",
    "    \n",
    "    # Residual connection avec D: y + u * D\n",
    "    ssm_flops['residual_D'] = B * L * d_inner * 2  # mult + add\n",
    "    \n",
    "    # ==================== OUTPUT PROCESSING ====================\n",
    "    \n",
    "    output_flops = {}\n",
    "    \n",
    "    # SiLU sur res: approximation 2 opérations par élément\n",
    "    output_flops['silu_res'] = B * L * d_inner * 2\n",
    "    \n",
    "    # Element-wise multiplication: y * silu(res)\n",
    "    output_flops['elementwise_mult'] = B * L * d_inner\n",
    "    \n",
    "    # Output projection: [B, L, d_inner] @ [d_inner, d_model] -> [B, L, d_model]\n",
    "    output_flops['out_proj'] = B * L * d_inner * d_model\n",
    "    \n",
    "    # ==================== RESIDUAL CONNECTION ====================\n",
    "    \n",
    "    residual_flops = {}\n",
    "    \n",
    "    # Residual add: mixer_output + input\n",
    "    residual_flops['residual_add'] = B * L * d_model\n",
    "    \n",
    "    # ==================== ASSEMBLY MAMBA LAYER FLOPS ====================\n",
    "    \n",
    "    # Somme des FLOPs pour une couche Mamba\n",
    "    mamba_layer_total = (sum(norm_flops.values()) + \n",
    "                        sum(mamba_block_flops.values()) + \n",
    "                        sum(conv_flops.values()) + \n",
    "                        sum(ssm_flops.values()) + \n",
    "                        sum(output_flops.values()) + \n",
    "                        sum(residual_flops.values()))\n",
    "    \n",
    "    mamba_layer_flops['norm'] = norm_flops\n",
    "    mamba_layer_flops['mamba_block'] = mamba_block_flops\n",
    "    mamba_layer_flops['conv'] = conv_flops\n",
    "    mamba_layer_flops['ssm'] = ssm_flops\n",
    "    mamba_layer_flops['output'] = output_flops\n",
    "    mamba_layer_flops['residual'] = residual_flops\n",
    "    mamba_layer_flops['total_per_layer'] = mamba_layer_total\n",
    "    \n",
    "    # ==================== FINAL NORMALIZATION ====================\n",
    "    \n",
    "    final_norm_flops = B * L * d_model * 3\n",
    "    \n",
    "    # ==================== OUTPUT LAYER ====================\n",
    "    \n",
    "    # Output linear layer: [B, L, d_model] @ [d_model, O] -> [B, L, O]\n",
    "    output_layer_flops = B * L * d_model * O\n",
    "    \n",
    "    # ==================== NORMALIZATION (pour forecasting) ====================\n",
    "    \n",
    "    normalization_flops = 0\n",
    "    if configs.get('task_name') in ['long_term_forecast', 'short_term_forecast']:\n",
    "        # Mean computation: B * L * I operations\n",
    "        normalization_flops += B * L * I\n",
    "        # Std computation: var + sqrt\n",
    "        normalization_flops += B * L * I * 2\n",
    "        # Normalization: subtract + divide\n",
    "        normalization_flops += B * L * I * 2\n",
    "        # Denormalization: multiply + add\n",
    "        normalization_flops += B * L * I * 2\n",
    "    \n",
    "    # ==================== TOTAL CALCULATION ====================\n",
    "    \n",
    "    flops_breakdown['input_embedding'] = flops_breakdown['input_embedding']\n",
    "    flops_breakdown['positional_temporal_embedding'] = flops_breakdown['positional_temporal_embedding']\n",
    "    flops_breakdown['mamba_layers'] = mamba_layer_flops\n",
    "    flops_breakdown['total_mamba_layers'] = mamba_layer_total * n_layers\n",
    "    flops_breakdown['final_norm'] = final_norm_flops\n",
    "    flops_breakdown['output_layer'] = output_layer_flops\n",
    "    flops_breakdown['normalization'] = normalization_flops\n",
    "    \n",
    "    total_flops = (flops_breakdown['input_embedding'] + \n",
    "                  flops_breakdown['positional_temporal_embedding'] +\n",
    "                  flops_breakdown['total_mamba_layers'] + \n",
    "                  flops_breakdown['final_norm'] +\n",
    "                  flops_breakdown['output_layer'] +\n",
    "                  flops_breakdown['normalization'])\n",
    "    \n",
    "    flops_breakdown['total'] = total_flops\n",
    "    \n",
    "    return flops_breakdown, total_flops\n",
    "\n",
    "def print_flops_breakdown_mamba(flops_breakdown, total_flops):\n",
    "    \"\"\"\n",
    "    Affiche un résumé détaillé des FLOPs pour le modèle Mamba.\n",
    "    Parameters:\n",
    "    - flops_breakdown: Dictionnaire des FLOPs par composant\n",
    "    - total_flops: Total des FLOPs\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(f\"MAMBA - FLOPs BREAKDOWN\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"Input Embedding: {flops_breakdown['input_embedding']:,} FLOPs\")\n",
    "    print(f\"Positional/Temporal Embedding: {flops_breakdown['positional_temporal_embedding']:,} FLOPs\")\n",
    "    print(f\"Final Norm: {flops_breakdown['final_norm']:,} FLOPs\")\n",
    "    print(f\"Output Layer: {flops_breakdown['output_layer']:,} FLOPs\")\n",
    "    if flops_breakdown['normalization'] > 0:\n",
    "        print(f\"Normalization: {flops_breakdown['normalization']:,} FLOPs\")\n",
    "    \n",
    "    print(f\"\\n=== MAMBA LAYERS ===\")\n",
    "    print(f\"Per Mamba Layer FLOPs: {flops_breakdown['mamba_layers']['total_per_layer']:,}\")\n",
    "    print(f\"Total Mamba Layers FLOPs: {flops_breakdown['total_mamba_layers']:,}\")\n",
    "    \n",
    "    print(f\"\\n--- Mamba Layer Breakdown ---\")\n",
    "    norm_total = sum(flops_breakdown['mamba_layers']['norm'].values())\n",
    "    mamba_block_total = sum(flops_breakdown['mamba_layers']['mamba_block'].values())\n",
    "    conv_total = sum(flops_breakdown['mamba_layers']['conv'].values())\n",
    "    ssm_total = sum(flops_breakdown['mamba_layers']['ssm'].values())\n",
    "    output_total = sum(flops_breakdown['mamba_layers']['output'].values())\n",
    "    residual_total = sum(flops_breakdown['mamba_layers']['residual'].values())\n",
    "    \n",
    "    layer_total = flops_breakdown['mamba_layers']['total_per_layer']\n",
    "    print(f\"RMS Normalization: {norm_total:,} FLOPs ({norm_total/layer_total*100:.1f}%)\")\n",
    "    print(f\"Input Projection: {mamba_block_total:,} FLOPs ({mamba_block_total/layer_total*100:.1f}%)\")\n",
    "    print(f\"Convolution 1D: {conv_total:,} FLOPs ({conv_total/layer_total*100:.1f}%)\")\n",
    "    print(f\"State Space Model: {ssm_total:,} FLOPs ({ssm_total/layer_total*100:.1f}%)\")\n",
    "    print(f\"Output Processing: {output_total:,} FLOPs ({output_total/layer_total*100:.1f}%)\")\n",
    "    print(f\"Residual Connection: {residual_total:,} FLOPs ({residual_total/layer_total*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n--- Detailed SSM Breakdown ---\")\n",
    "    for component, flops in flops_breakdown['mamba_layers']['ssm'].items():\n",
    "        print(f\"  {component}: {flops:,} FLOPs\")\n",
    "    \n",
    "    print(f\"\\n--- Detailed Conv Breakdown ---\")\n",
    "    for component, flops in flops_breakdown['mamba_layers']['conv'].items():\n",
    "        print(f\"  {component}: {flops:,} FLOPs\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"TOTAL FLOPs: {total_flops:,}\")\n",
    "    print(f\"TOTAL GFLOPs: {total_flops / 1e9:.3f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Test du modèle Mamba\n",
    "from models.MambaSimple import Model as MambaSimple\n",
    "import math\n",
    "\n",
    "# Configuration pour le modèle Mamba\n",
    "conf_mamba = {\n",
    "    'task_name': 'anomaly_detection',\n",
    "    'pred_len': 96,\n",
    "    'seq_len': 96,\n",
    "    'enc_in': 10,        # Features d'entrée\n",
    "    'c_out': 10,         # Features de sortie\n",
    "    'd_model': 192,       # Dimension du modèle\n",
    "    'expand': 2,         # Facteur d'expansion (d_inner = d_model * expand)\n",
    "    'd_conv': 8,         # Taille du kernel de convolution\n",
    "    'd_ff': 256,          # Dimension état SSM\n",
    "    'e_layers': 2,       # Nombre de couches\n",
    "    'dropout': 0.1,\n",
    "    'embed': 'timeF',\n",
    "    'freq': 'h'\n",
    "}\n",
    "configs_mamba = type('Config', (), conf_mamba)()\n",
    "\n",
    "# Créer le modèle Mamba\n",
    "model_mamba = MambaSimple(configs_mamba)\n",
    "print(\"Model parameters:\", sum(p.numel() for p in model_mamba.parameters()))\n",
    "\n",
    "print(\"=== MODÈLE MAMBA CRÉÉ ===\")\n",
    "print(f\"Task: {model_mamba.task_name}\")\n",
    "print(f\"d_inner: {model_mamba.d_inner}\")\n",
    "print(f\"dt_rank: {model_mamba.dt_rank}\")\n",
    "print(f\"Layers: {len(model_mamba.layers)}\")\n",
    "\n",
    "# Test des FLOPs\n",
    "batch_size = 32\n",
    "sequence_length = 96\n",
    "\n",
    "flops_breakdown, total_flops = count_flops_mamba(\n",
    "    model_mamba, batch_size=batch_size, sequence_length=sequence_length, configs=conf_mamba\n",
    ")\n",
    "\n",
    "# Afficher les résultats\n",
    "print_flops_breakdown_mamba(flops_breakdown, total_flops)\n",
    "\n",
    "# Test avec différentes longueurs de séquence\n",
    "print(f\"\\n=== TEST AVEC DIFFÉRENTES LONGUEURS DE SÉQUENCE ===\")\n",
    "flops_mamba = []\n",
    "\n",
    "for seq_len in SEQ_LENGTHS:\n",
    "    flops_breakdown, total_flops = count_flops_mamba(\n",
    "        model_mamba, batch_size=10, sequence_length=seq_len, configs=conf_mamba\n",
    "    )\n",
    "    print(f\"Sequence Length: {seq_len:4d}, Total FLOPs: {total_flops:12,}, GFLOPs: {total_flops/1e9:8.3f}\")\n",
    "    flops_mamba.append(total_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465537e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def count_flops_reformer_fixed(model, batch_size=1, sequence_length=1, configs={}):\n",
    "    B = batch_size\n",
    "    L = sequence_length\n",
    "\n",
    "    d_model = configs['d_model']\n",
    "    n_heads = configs['n_heads']\n",
    "    d_ff = configs['d_ff']\n",
    "    e_layers = configs['e_layers']\n",
    "    bucket_size = configs.get('bucket_size', 64)   # typiquement plus grand que 4 pour expérimenter scaling\n",
    "    n_hashes = configs.get('n_hashes', 2)\n",
    "    I = configs.get('enc_in', 1)\n",
    "    O = configs.get('c_out', 1)\n",
    "    head_dim = d_model // n_heads\n",
    "    # constants: we count multiply+add as 2 FLOPs per MAC when appropriate\n",
    "    flops = {}\n",
    "    # Input embedding (linear): B * L * I * d_model * 2 (mul+add)\n",
    "    flops['input_embedding'] = 2 * B * L * I * d_model\n",
    "    flops['temporal_embedding'] = 2 * B * L * 4 * d_model\n",
    "\n",
    "    # ----- Per encoder layer -----\n",
    "    per_layer = {}\n",
    "    # QKV projections: 3 × (B * L * d_model * d_model * 2)\n",
    "    per_layer['QKV_proj'] = 3 * 2 * B * L * d_model * d_model\n",
    "\n",
    "    # Output projection after heads (W_o : d_model x d_model)\n",
    "    per_layer['output_proj'] = 2 * B * L * d_model * d_model\n",
    "\n",
    "    # LSH hashing cost: approximate cost to compute hashes (random projection) ~ 2 * d_model per hash\n",
    "    per_layer['hash_proj'] = 2 * B * n_heads * n_hashes * L * d_model\n",
    "\n",
    "    # Sorting cost (dominant L log L term): we model as c_sort * B * n_heads * n_hashes * L * log2(L)\n",
    "    c_sort = 1.0   # coefficient (depends on sort implementation) — tune if needed\n",
    "    per_layer['bucket_sorting'] = c_sort * B * n_heads * n_hashes * L * math.log2(max(2, L))\n",
    "\n",
    "    # Attention inside buckets:\n",
    "    # number of buckets = ceil(L / bucket_size)\n",
    "    num_buckets = max(1, math.ceil(L / bucket_size))\n",
    "    # cost per bucket: for a bucket of size b, score computation ~ b^2 * head_dim * 2 (QK^T multiplies+adds)\n",
    "    # assume most buckets have size ~bucket_size, last may be smaller\n",
    "    b = bucket_size\n",
    "    per_layer['bucket_attention_scores'] = 2 * B * n_heads * num_buckets * (b * b) * head_dim\n",
    "    # softmax cost (approx 5 ops per element)\n",
    "    per_layer['bucket_softmax'] = 5 * B * n_heads * num_buckets * (b * b)\n",
    "    # attention @ V: b^2 * head_dim * 2\n",
    "    per_layer['bucket_weighted_values'] = 2 * B * n_heads * num_buckets * (b * b) * head_dim\n",
    "\n",
    "    # residual + layernorm approx\n",
    "    per_layer['residual_add'] = B * L * d_model\n",
    "    per_layer['layer_norm'] = 6 * B * L * d_model  # mean,var,scale,shift approximated\n",
    "\n",
    "    # Reversible feed-forward (applied to halves)\n",
    "    d_half = d_model // 2\n",
    "    # F/G each: linear1 (d_half -> d_ff), activation, linear2 (d_ff -> d_half)\n",
    "    per_layer['FF_linear1'] = 2 * B * L * d_half * d_ff\n",
    "    per_layer['FF_activation'] = 2 * B * L * d_ff\n",
    "    per_layer['FF_linear2'] = 2 * B * L * d_ff * d_half\n",
    "\n",
    "    per_layer_total = sum(per_layer.values())\n",
    "    flops['per_encoder_layer'] = per_layer\n",
    "    flops['per_encoder_layer_total'] = per_layer_total\n",
    "    flops['total_encoder'] = per_layer_total * e_layers\n",
    "\n",
    "    # final encoder norm\n",
    "    flops['encoder_norm'] = 6 * B * L * d_model\n",
    "\n",
    "    # output projection (anomaly detection / imputation)\n",
    "    flops['output'] = 2 * B * L * d_model * O\n",
    "\n",
    "    total = (flops['input_embedding'] + flops['temporal_embedding'] +\n",
    "             flops['total_encoder'] + flops['encoder_norm'] + flops['output'])\n",
    "\n",
    "    return flops, total\n",
    "\n",
    "def count_flops_reformer(model, batch_size=1, sequence_length=1, configs={}):\n",
    "    \"\"\"\n",
    "    Compte les FLOPs (Floating Point Operations) pour le modèle Reformer.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Instance du modèle Reformer\n",
    "    - batch_size: Taille du batch\n",
    "    - sequence_length: Longueur de la séquence\n",
    "    - configs: Configuration du modèle (dict)\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionnaire détaillé des FLOPs par composant\n",
    "    - int: Total des FLOPs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Paramètres du modèle\n",
    "    B = batch_size\n",
    "    L = sequence_length  # Sequence length\n",
    "    \n",
    "    # Récupérer les paramètres depuis la configuration\n",
    "    d_model = configs.get('d_model')  # Dimension du modèle\n",
    "    n_heads = configs.get('n_heads')  # Nombre de têtes d'attention\n",
    "    d_ff = configs.get('d_ff')  # Dimension feedforward\n",
    "    e_layers = configs.get('e_layers')  # Nombre de couches encoder\n",
    "    bucket_size = configs.get('bucket_size', 4)  # Taille des buckets pour LSH\n",
    "    n_hashes = configs.get('n_hashes', 4)  # Nombre de hash functions\n",
    "    \n",
    "    # Input/Output dimensions\n",
    "    I = configs.get('enc_in')  # Input features\n",
    "    O = configs.get('c_out')  # Output features\n",
    "    \n",
    "    # Dimension par tête d'attention\n",
    "    head_dim = d_model // n_heads\n",
    "    \n",
    "    flops_breakdown = {}\n",
    "    \n",
    "    # ==================== INPUT EMBEDDING ====================\n",
    "    \n",
    "    # Input embedding (DataEmbedding)\n",
    "    # Value embedding: Linear [I -> d_model]\n",
    "    flops_breakdown['input_embedding'] = B * L * I * d_model\n",
    "    \n",
    "    # Positional embedding (sinusoidal)\n",
    "    # Addition seulement, pas de FLOPs\n",
    "    \n",
    "    # Temporal embedding (si applicable)\n",
    "    # Approximation: embedding temporel basé sur les features temporelles\n",
    "    flops_breakdown['temporal_embedding'] = B * L * 4 * d_model  # 4 features temporelles typiques\n",
    "    \n",
    "    # ==================== ENCODER LAYERS ====================\n",
    "    \n",
    "    encoder_layer_flops = {}\n",
    "    \n",
    "    # ==================== LOCALITY SENSITIVE HASHING (LSH) ATTENTION ====================\n",
    "    \n",
    "    lsh_attention_flops = {}\n",
    "    \n",
    "    # Query, Key, Value projections\n",
    "    lsh_attention_flops['Q_projection'] = B * L * d_model * d_model\n",
    "    lsh_attention_flops['K_projection'] = B * L * d_model * d_model\n",
    "    lsh_attention_flops['V_projection'] = B * L * d_model * d_model\n",
    "    \n",
    "    # Reshape pour multi-head: [B, L, d_model] -> [B, n_heads, L, head_dim]\n",
    "    # Pas de FLOPs, juste un reshape\n",
    "    \n",
    "    # ==================== LSH ATTENTION CORRIGÉE ====================\n",
    "\n",
    "    # Hashing reste O(L log L)\n",
    "    lsh_attention_flops['bucket_sorting'] = B * n_heads * n_hashes * L * math.log2(L)\n",
    "\n",
    "    # Attention dans les buckets - COMPLEXITÉ FIXE\n",
    "    # Chaque bucket a une taille fixe (bucket_size = 4)\n",
    "    # Nombre total d'opérations d'attention : O(L * bucket_size) au lieu de O(L²)\n",
    "    effective_bucket_size = bucket_size  # Taille fixe, pas dépendante de L\n",
    "    num_attention_ops = L * effective_bucket_size  # O(L) au lieu de O(L²)\n",
    "\n",
    "    lsh_attention_flops['bucket_attention_scores'] = B * n_heads * num_attention_ops * head_dim\n",
    "    lsh_attention_flops['bucket_attention_softmax'] = B * n_heads * num_attention_ops * 3\n",
    "    lsh_attention_flops['bucket_attention_values'] = B * n_heads * num_attention_ops * head_dim\n",
    "    \n",
    "    # # ==================== ATTENTION DANS LES BUCKETS ====================\n",
    "    \n",
    "    # # Nombre moyen d'éléments par bucket\n",
    "    # avg_bucket_size = max(1, min(bucket_size, L // (2 ** (n_hashes // 2))))  # Approximation heuristique\n",
    "    # num_buckets = max(1, L // avg_bucket_size)\n",
    "    \n",
    "    # # Attention computation dans chaque bucket\n",
    "    # # Au lieu de O(L²), on a O(bucket_size²) par bucket\n",
    "    # lsh_attention_flops['bucket_attention_scores'] = B * n_heads * num_buckets * avg_bucket_size * head_dim * avg_bucket_size\n",
    "    \n",
    "    # # Scale by sqrt(head_dim)\n",
    "    # lsh_attention_flops['scale_attention'] = B * n_heads * num_buckets * avg_bucket_size * avg_bucket_size\n",
    "    \n",
    "    # # Softmax dans chaque bucket\n",
    "    # lsh_attention_flops['bucket_attention_softmax'] = B * n_heads * num_buckets * avg_bucket_size * avg_bucket_size * 3\n",
    "    \n",
    "    # # Attention weights @ V dans chaque bucket\n",
    "    # lsh_attention_flops['bucket_attention_values'] = B * n_heads * num_buckets * avg_bucket_size * avg_bucket_size * head_dim\n",
    "    \n",
    "    # # Reassembly des résultats des buckets\n",
    "    # lsh_attention_flops['bucket_reassembly'] = B * n_heads * L * head_dim\n",
    "    \n",
    "    # # Output projection\n",
    "    # lsh_attention_flops['output_projection'] = B * L * d_model * d_model\n",
    "    \n",
    "    # # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # # Residual connection + Layer Norm\n",
    "    # lsh_attention_flops['residual_add'] = B * L * d_model\n",
    "    # lsh_attention_flops['layer_norm1'] = B * L * d_model * 3  # mean, var, normalize\n",
    "    \n",
    "    # ==================== REVERSIBLE RESIDUAL LAYERS ====================\n",
    "    \n",
    "    # Reformer utilise des couches réversibles qui divisent d_model en 2\n",
    "    # F(x1) + x2 et G(x2) + x1 où F et G sont des sous-réseaux\n",
    "    \n",
    "    reversible_flops = {}\n",
    "    \n",
    "    # Chunking: diviser d_model en 2 parties (pas de FLOPs)\n",
    "    d_model_half = d_model // 2\n",
    "    \n",
    "    # F function (Feed Forward sur la première moitié)\n",
    "    reversible_flops['F_linear1'] = B * L * d_model_half * d_ff\n",
    "    reversible_flops['F_activation'] = B * L * d_ff * 2  # GELU\n",
    "    reversible_flops['F_linear2'] = B * L * d_ff * d_model_half\n",
    "    \n",
    "    # Addition F(x1) + x2\n",
    "    reversible_flops['F_residual_add'] = B * L * d_model_half\n",
    "    \n",
    "    # G function (identique à F mais sur la deuxième moitié)\n",
    "    reversible_flops['G_linear1'] = B * L * d_model_half * d_ff\n",
    "    reversible_flops['G_activation'] = B * L * d_ff * 2  # GELU\n",
    "    reversible_flops['G_linear2'] = B * L * d_ff * d_model_half\n",
    "    \n",
    "    # Addition G(x2) + x1\n",
    "    reversible_flops['G_residual_add'] = B * L * d_model_half\n",
    "    \n",
    "    # Concatenation finale (pas de FLOPs)\n",
    "    \n",
    "    # Layer Norm finale\n",
    "    reversible_flops['layer_norm2'] = B * L * d_model * 3\n",
    "    \n",
    "    # ==================== ASSEMBLY ENCODER LAYER FLOPS ====================\n",
    "    \n",
    "    encoder_layer_total = (sum(lsh_attention_flops.values()) + \n",
    "                          sum(reversible_flops.values()))\n",
    "    \n",
    "    encoder_layer_flops['lsh_attention'] = lsh_attention_flops\n",
    "    encoder_layer_flops['reversible_layers'] = reversible_flops\n",
    "    encoder_layer_flops['total_per_layer'] = encoder_layer_total\n",
    "    \n",
    "    # ==================== FINAL ENCODER NORMALIZATION ====================\n",
    "    \n",
    "    encoder_norm_flops = B * L * d_model * 3\n",
    "    \n",
    "    # ==================== OUTPUT PROJECTION ====================\n",
    "    \n",
    "    output_flops = 0\n",
    "    \n",
    "    if configs.get('task_name') == 'classification':\n",
    "        # GELU activation: [B, L, d_model]\n",
    "        gelu_flops = B * L * d_model * 2\n",
    "        # Dropout (pas de FLOPs)\n",
    "        # Reshape: [B, L * d_model]\n",
    "        # Projection: [B, L * d_model] @ [L * d_model, num_class] -> [B, num_class]\n",
    "        num_class = configs.get('num_class', O)\n",
    "        projection_flops = B * (L * d_model) * num_class\n",
    "        \n",
    "        output_flops = gelu_flops + projection_flops\n",
    "        flops_breakdown['output_activation'] = gelu_flops\n",
    "        flops_breakdown['output_projection'] = projection_flops\n",
    "        \n",
    "    elif configs.get('task_name') in ['imputation', 'anomaly_detection']:\n",
    "        # Direct projection: [B, L, d_model] @ [d_model, O] -> [B, L, O]\n",
    "        output_flops = B * L * d_model * O\n",
    "        flops_breakdown['output_projection'] = output_flops\n",
    "        \n",
    "    elif configs.get('task_name') in ['long_term_forecast', 'short_term_forecast']:\n",
    "        # Pour forecasting, on ajoute un placeholder et projette\n",
    "        pred_len = configs.get('pred_len', L)\n",
    "        total_len = L + pred_len\n",
    "        \n",
    "        # Embedding du placeholder\n",
    "        placeholder_embedding_flops = B * pred_len * I * d_model\n",
    "        \n",
    "        # Encoder avec longueur étendue\n",
    "        extended_encoder_flops = encoder_layer_total * e_layers * (total_len / L)  # Proportionnel à la longueur\n",
    "        \n",
    "        # Projection finale\n",
    "        forecast_projection_flops = B * total_len * d_model * O\n",
    "        \n",
    "        # Normalization pour short_term_forecast\n",
    "        normalization_flops = 0\n",
    "        if configs.get('task_name') == 'short_term_forecast':\n",
    "            # Mean et std computation\n",
    "            normalization_flops += B * L * I * 3  # mean + var + sqrt\n",
    "            # Normalization et denormalization\n",
    "            normalization_flops += B * total_len * I * 4  # subtract + divide + multiply + add\n",
    "        \n",
    "        flops_breakdown['placeholder_embedding'] = placeholder_embedding_flops\n",
    "        flops_breakdown['extended_encoder'] = extended_encoder_flops\n",
    "        flops_breakdown['forecast_projection'] = forecast_projection_flops\n",
    "        flops_breakdown['forecast_normalization'] = normalization_flops\n",
    "        \n",
    "        output_flops = (placeholder_embedding_flops + extended_encoder_flops + \n",
    "                       forecast_projection_flops + normalization_flops)\n",
    "    \n",
    "    # ==================== TOTAL CALCULATION ====================\n",
    "    \n",
    "    flops_breakdown['input_embedding'] = flops_breakdown['input_embedding']\n",
    "    flops_breakdown['temporal_embedding'] = flops_breakdown['temporal_embedding']\n",
    "    flops_breakdown['encoder_layers'] = encoder_layer_flops\n",
    "    flops_breakdown['total_encoder_layers'] = encoder_layer_total * e_layers\n",
    "    flops_breakdown['encoder_norm'] = encoder_norm_flops\n",
    "    \n",
    "    total_flops = (flops_breakdown['input_embedding'] + \n",
    "                  flops_breakdown['temporal_embedding'] +\n",
    "                  flops_breakdown['total_encoder_layers'] + \n",
    "                  flops_breakdown['encoder_norm'] +\n",
    "                  output_flops)\n",
    "    \n",
    "    flops_breakdown['total'] = total_flops\n",
    "    \n",
    "    return flops_breakdown, total_flops\n",
    "\n",
    "def print_flops_breakdown_reformer(flops_breakdown, total_flops):\n",
    "    \"\"\"\n",
    "    Affiche un résumé détaillé des FLOPs pour le modèle Reformer.\n",
    "    \n",
    "    Parameters:\n",
    "    - flops_breakdown: Dictionnaire des FLOPs par composant\n",
    "    - total_flops: Total des FLOPs\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(f\"REFORMER - FLOPs BREAKDOWN\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"Input Embedding: {flops_breakdown['input_embedding']:,} FLOPs\")\n",
    "    print(f\"Temporal Embedding: {flops_breakdown['temporal_embedding']:,} FLOPs\")\n",
    "    print(f\"Encoder Norm: {flops_breakdown['encoder_norm']:,} FLOPs\")\n",
    "    \n",
    "    if 'output_projection' in flops_breakdown:\n",
    "        print(f\"Output Projection: {flops_breakdown['output_projection']:,} FLOPs\")\n",
    "    if 'output_activation' in flops_breakdown:\n",
    "        print(f\"Output Activation: {flops_breakdown['output_activation']:,} FLOPs\")\n",
    "    \n",
    "    # Forecasting specific components\n",
    "    if 'placeholder_embedding' in flops_breakdown:\n",
    "        print(f\"Placeholder Embedding: {flops_breakdown['placeholder_embedding']:,} FLOPs\")\n",
    "        print(f\"Extended Encoder: {flops_breakdown['extended_encoder']:,} FLOPs\")\n",
    "        print(f\"Forecast Projection: {flops_breakdown['forecast_projection']:,} FLOPs\")\n",
    "        if flops_breakdown['forecast_normalization'] > 0:\n",
    "            print(f\"Forecast Normalization: {flops_breakdown['forecast_normalization']:,} FLOPs\")\n",
    "    \n",
    "    print(f\"\\n=== ENCODER ===\")\n",
    "    print(f\"Per Encoder Layer FLOPs: {flops_breakdown['encoder_layers']['total_per_layer']:,}\")\n",
    "    print(f\"Total Encoder Layers FLOPs: {flops_breakdown['total_encoder_layers']:,}\")\n",
    "    \n",
    "    print(f\"\\n--- Encoder Layer Breakdown ---\")\n",
    "    lsh_attention_total = sum(flops_breakdown['encoder_layers']['lsh_attention'].values())\n",
    "    reversible_total = sum(flops_breakdown['encoder_layers']['reversible_layers'].values())\n",
    "    encoder_layer_total = flops_breakdown['encoder_layers']['total_per_layer']\n",
    "    \n",
    "    print(f\"LSH Attention: {lsh_attention_total:,} FLOPs ({lsh_attention_total/encoder_layer_total*100:.1f}%)\")\n",
    "    print(f\"Reversible Layers: {reversible_total:,} FLOPs ({reversible_total/encoder_layer_total*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n--- Detailed LSH Attention Breakdown ---\")\n",
    "    for component, flops in flops_breakdown['encoder_layers']['lsh_attention'].items():\n",
    "        print(f\"  {component}: {flops:,} FLOPs\")\n",
    "    \n",
    "    print(f\"\\n--- Detailed Reversible Layers Breakdown ---\")\n",
    "    for component, flops in flops_breakdown['encoder_layers']['reversible_layers'].items():\n",
    "        print(f\"  {component}: {flops:,} FLOPs\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"TOTAL FLOPs: {total_flops:,}\")\n",
    "    print(f\"TOTAL GFLOPs: {total_flops / 1e9:.3f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "\n",
    "# Test du modèle Reformer\n",
    "from models.Reformer import Model as Reformer\n",
    "import math\n",
    "\n",
    "# Configuration pour le modèle Reformer\n",
    "conf_reformer = {\n",
    "    'task_name': 'anomaly_detection',\n",
    "    'seq_len': 96,\n",
    "    'pred_len': 96,\n",
    "    'enc_in': 10,        # Features d'entrée\n",
    "    'c_out': 10,         # Features de sortie\n",
    "    'num_class': 10,     # Nombre de classes pour classification\n",
    "    'd_model': 280,       # Dimension du modèle (doit être pair pour les couches réversibles)\n",
    "    'n_heads': 8,        # Nombre de têtes d'attention\n",
    "    'd_ff': 512,         # Dimension feedforward\n",
    "    'e_layers': 2,       # Nombre de couches encoder\n",
    "    'bucket_size': 4,    # Taille des buckets pour LSH\n",
    "    'n_hashes': 2,       # Nombre de hash functions\n",
    "    'dropout': 0.1,\n",
    "    'activation': 'gelu',\n",
    "    'embed': 'timeF',\n",
    "    'freq': 'h'\n",
    "}\n",
    "configs_reformer = type('Config', (), conf_reformer)()\n",
    "\n",
    "# Créer le modèle Reformer\n",
    "model_reformer = Reformer(configs_reformer, \n",
    "                         bucket_size=conf_reformer['bucket_size'],\n",
    "                         n_hashes=conf_reformer['n_hashes'])\n",
    "print(\"Model parameters:\", sum(p.numel() for p in model_reformer.parameters()))\n",
    "\n",
    "# Test des FLOPs\n",
    "batch_size = 32\n",
    "sequence_length = 96\n",
    "\n",
    "flops_breakdown, total_flops = count_flops_reformer(\n",
    "    model_reformer, batch_size=batch_size, sequence_length=sequence_length, configs=conf_reformer\n",
    ")\n",
    "\n",
    "# Afficher les résultats\n",
    "print_flops_breakdown_reformer(flops_breakdown, total_flops)\n",
    "\n",
    "# Test avec différentes longueurs de séquence\n",
    "print(f\"\\n=== TEST AVEC DIFFÉRENTES LONGUEURS DE SÉQUENCE ===\")\n",
    "flops_reformer = []\n",
    "\n",
    "for seq_len in SEQ_LENGTHS:\n",
    "    # Ajuster la configuration pour chaque longueur de séquence\n",
    "    conf_test = conf_reformer.copy()\n",
    "    conf_test['seq_len'] = seq_len\n",
    "    \n",
    "    flops_breakdown, total_flops = count_flops_reformer(\n",
    "        model_reformer, batch_size=10, sequence_length=seq_len, configs=conf_test\n",
    "    )\n",
    "    print(f\"Sequence Length: {seq_len:4d}, Total FLOPs: {total_flops:12,}, GFLOPs: {total_flops/1e9:8.3f}\")\n",
    "    flops_reformer.append(total_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ebb134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_flops_itransformer(model, batch_size=1, sequence_length=1, configs={}):\n",
    "    \"\"\"\n",
    "    Compte les FLOPs (Floating Point Operations) pour le modèle iTransformer.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Instance du modèle iTransformer\n",
    "    - batch_size: Taille du batch\n",
    "    - sequence_length: Longueur de la séquence\n",
    "    - configs: Configuration du modèle (dict)\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionnaire détaillé des FLOPs par composant\n",
    "    - int: Total des FLOPs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Paramètres du modèle\n",
    "    B = batch_size\n",
    "    L = sequence_length  # Sequence length\n",
    "    \n",
    "    # Récupérer les paramètres depuis la configuration\n",
    "    d_model = configs.get('d_model')  # Dimension du modèle\n",
    "    n_heads = configs.get('n_heads')  # Nombre de têtes d'attention\n",
    "    d_ff = configs.get('d_ff')  # Dimension feedforward\n",
    "    e_layers = configs.get('e_layers')  # Nombre de couches encoder\n",
    "    \n",
    "    # Input/Output dimensions\n",
    "    N = configs.get('enc_in')  # Number of variables (features)\n",
    "    \n",
    "    # Output dimension selon la tâche\n",
    "    if configs.get('task_name') == 'classification':\n",
    "        O = configs.get('num_class')\n",
    "    elif configs.get('task_name') in ['long_term_forecast', 'short_term_forecast']:\n",
    "        O = configs.get('pred_len')\n",
    "    else:  # imputation, anomaly_detection\n",
    "        O = L  # seq_len\n",
    "    \n",
    "    # Dimension par tête d'attention\n",
    "    head_dim = d_model // n_heads\n",
    "    \n",
    "    flops_breakdown = {}\n",
    "    \n",
    "    # ==================== NORMALIZATION (pour forecasting/imputation/anomaly) ====================\n",
    "    \n",
    "    normalization_flops = 0\n",
    "    if configs.get('task_name') in ['long_term_forecast', 'short_term_forecast', 'imputation', 'anomaly_detection']:\n",
    "        # Mean computation: [B, L, N] -> [B, 1, N]\n",
    "        normalization_flops += B * L * N  # sum\n",
    "        normalization_flops += B * N      # divide par L\n",
    "        \n",
    "        # Variance computation: [B, L, N]\n",
    "        normalization_flops += B * L * N  # subtract mean\n",
    "        normalization_flops += B * L * N  # square\n",
    "        normalization_flops += B * L * N  # sum\n",
    "        normalization_flops += B * N      # divide par L\n",
    "        normalization_flops += B * N      # sqrt\n",
    "        \n",
    "        # Normalization: [B, L, N]\n",
    "        normalization_flops += B * L * N  # subtract mean\n",
    "        normalization_flops += B * L * N  # divide by std\n",
    "        \n",
    "        # Denormalization (en sortie)\n",
    "        if configs.get('task_name') in ['long_term_forecast', 'short_term_forecast']:\n",
    "            pred_len = configs.get('pred_len', L)\n",
    "            normalization_flops += B * pred_len * N * 2  # multiply + add\n",
    "        else:\n",
    "            normalization_flops += B * L * N * 2  # multiply + add\n",
    "    \n",
    "    # ==================== INVERTED EMBEDDING ====================\n",
    "    \n",
    "    # iTransformer utilise DataEmbedding_inverted\n",
    "    # Input: [B, L, N] -> Transposed: [B, N, L]\n",
    "    # Chaque variable devient une séquence de longueur L\n",
    "    \n",
    "    # Value embedding: Linear projection [L -> d_model] pour chaque variable\n",
    "    flops_breakdown['input_embedding'] = B * N * L * d_model\n",
    "    \n",
    "    # Temporal embedding (si applicable)\n",
    "    # Pour chaque variable, on applique l'embedding temporel\n",
    "    flops_breakdown['temporal_embedding'] = B * N * 4 * d_model  # 4 features temporelles typiques\n",
    "    \n",
    "    # ==================== ENCODER LAYERS ====================\n",
    "    \n",
    "    encoder_layer_flops = {}\n",
    "    \n",
    "    # ==================== MULTI-HEAD ATTENTION ====================\n",
    "    \n",
    "    attention_flops = {}\n",
    "    \n",
    "    # Dans iTransformer, l'attention s'applique sur les variables (dimension N)\n",
    "    # Input shape après embedding: [B, N, d_model]\n",
    "    \n",
    "    # Query, Key, Value projections\n",
    "    # Input: [B, N, d_model] -> Output: [B, N, d_model] (pour chacune des 3 projections)\n",
    "    attention_flops['Q_projection'] = B * N * d_model * d_model\n",
    "    attention_flops['K_projection'] = B * N * d_model * d_model\n",
    "    attention_flops['V_projection'] = B * N * d_model * d_model\n",
    "    \n",
    "    # Reshape pour multi-head: [B, N, d_model] -> [B, n_heads, N, head_dim]\n",
    "    # Pas de FLOPs, juste un reshape\n",
    "    \n",
    "    # Attention scores: Q @ K^T\n",
    "    # Q: [B, n_heads, N, head_dim], K^T: [B, n_heads, head_dim, N] -> [B, n_heads, N, N]\n",
    "    attention_flops['attention_scores'] = B * n_heads * N * head_dim * N\n",
    "    \n",
    "    # Scale by sqrt(head_dim)\n",
    "    attention_flops['scale_attention'] = B * n_heads * N * N\n",
    "    \n",
    "    # Softmax sur la dimension des clés (N)\n",
    "    # Approximation: exp + sum + divide = 3 opérations par élément\n",
    "    attention_flops['attention_softmax'] = B * n_heads * N * N * 3\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # Attention weights @ V: [B, n_heads, N, N] @ [B, n_heads, N, head_dim] -> [B, n_heads, N, head_dim]\n",
    "    attention_flops['attention_values'] = B * n_heads * N * N * head_dim\n",
    "    \n",
    "    # Concatenate heads: [B, n_heads, N, head_dim] -> [B, N, d_model]\n",
    "    # Pas de FLOPs, juste un reshape\n",
    "    \n",
    "    # Output projection: [B, N, d_model] @ [d_model, d_model] -> [B, N, d_model]\n",
    "    attention_flops['output_projection'] = B * N * d_model * d_model\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # Residual connection + LayerNorm1\n",
    "    attention_flops['residual_add'] = B * N * d_model\n",
    "    attention_flops['layer_norm1'] = B * N * d_model * 3  # mean, var, normalize\n",
    "    \n",
    "    # ==================== FEED FORWARD NETWORK ====================\n",
    "    \n",
    "    feedforward_flops = {}\n",
    "    \n",
    "    # Linear 1: [B, N, d_model] -> [B, N, d_ff]\n",
    "    feedforward_flops['linear1'] = B * N * d_model * d_ff\n",
    "    \n",
    "    # Activation (GELU)\n",
    "    # Approximation: 2 opérations par élément pour GELU\n",
    "    feedforward_flops['activation'] = B * N * d_ff * 2\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # Linear 2: [B, N, d_ff] -> [B, N, d_model]\n",
    "    feedforward_flops['linear2'] = B * N * d_ff * d_model\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # Residual connection + LayerNorm2\n",
    "    feedforward_flops['residual_add'] = B * N * d_model\n",
    "    feedforward_flops['layer_norm2'] = B * N * d_model * 3\n",
    "    \n",
    "    # ==================== ASSEMBLY ENCODER LAYER FLOPS ====================\n",
    "    \n",
    "    encoder_layer_total = sum(attention_flops.values()) + sum(feedforward_flops.values())\n",
    "    \n",
    "    encoder_layer_flops['attention'] = attention_flops\n",
    "    encoder_layer_flops['feedforward'] = feedforward_flops\n",
    "    encoder_layer_flops['total_per_layer'] = encoder_layer_total\n",
    "    \n",
    "    # ==================== FINAL ENCODER NORMALIZATION ====================\n",
    "    \n",
    "    encoder_norm_flops = B * N * d_model * 3\n",
    "    \n",
    "    # ==================== OUTPUT PROJECTION ====================\n",
    "    \n",
    "    output_flops = 0\n",
    "    \n",
    "    if configs.get('task_name') == 'classification':\n",
    "        # GELU activation: [B, N, d_model]\n",
    "        gelu_flops = B * N * d_model * 2\n",
    "        # Dropout (pas de FLOPs)\n",
    "        # Reshape: [B, N * d_model]\n",
    "        # Projection: [B, N * d_model] @ [N * d_model, num_class] -> [B, num_class]\n",
    "        projection_flops = B * (N * d_model) * O\n",
    "        \n",
    "        output_flops = gelu_flops + projection_flops\n",
    "        flops_breakdown['output_activation'] = gelu_flops\n",
    "        flops_breakdown['output_projection'] = projection_flops\n",
    "        \n",
    "    elif configs.get('task_name') in ['long_term_forecast', 'short_term_forecast']:\n",
    "        # Projection: [B, N, d_model] @ [d_model, pred_len] -> [B, N, pred_len]\n",
    "        # Puis permute: [B, N, pred_len] -> [B, pred_len, N]\n",
    "        output_flops = B * N * d_model * O\n",
    "        flops_breakdown['output_projection'] = output_flops\n",
    "        \n",
    "    elif configs.get('task_name') in ['imputation', 'anomaly_detection']:\n",
    "        # Projection: [B, N, d_model] @ [d_model, seq_len] -> [B, N, seq_len]\n",
    "        # Puis permute: [B, N, seq_len] -> [B, seq_len, N]\n",
    "        output_flops = B * N * d_model * O\n",
    "        flops_breakdown['output_projection'] = output_flops\n",
    "    \n",
    "    # ==================== TOTAL CALCULATION ====================\n",
    "    \n",
    "    flops_breakdown['normalization'] = normalization_flops\n",
    "    flops_breakdown['input_embedding'] = flops_breakdown['input_embedding']\n",
    "    flops_breakdown['temporal_embedding'] = flops_breakdown['temporal_embedding']\n",
    "    flops_breakdown['encoder_layers'] = encoder_layer_flops\n",
    "    flops_breakdown['total_encoder_layers'] = encoder_layer_total * e_layers\n",
    "    flops_breakdown['encoder_norm'] = encoder_norm_flops\n",
    "    \n",
    "    total_flops = (flops_breakdown['normalization'] +\n",
    "                  flops_breakdown['input_embedding'] + \n",
    "                  flops_breakdown['temporal_embedding'] +\n",
    "                  flops_breakdown['total_encoder_layers'] + \n",
    "                  flops_breakdown['encoder_norm'] +\n",
    "                  output_flops)\n",
    "    \n",
    "    flops_breakdown['total'] = total_flops\n",
    "    \n",
    "    return flops_breakdown, total_flops\n",
    "\n",
    "def print_flops_breakdown_itransformer(flops_breakdown, total_flops):\n",
    "    \"\"\"\n",
    "    Affiche un résumé détaillé des FLOPs pour le modèle iTransformer.\n",
    "    \n",
    "    Parameters:\n",
    "    - flops_breakdown: Dictionnaire des FLOPs par composant\n",
    "    - total_flops: Total des FLOPs\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(f\"iTRANSFORMER - FLOPs BREAKDOWN\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if flops_breakdown['normalization'] > 0:\n",
    "        print(f\"Normalization: {flops_breakdown['normalization']:,} FLOPs\")\n",
    "    print(f\"Input Embedding (Inverted): {flops_breakdown['input_embedding']:,} FLOPs\")\n",
    "    print(f\"Temporal Embedding: {flops_breakdown['temporal_embedding']:,} FLOPs\")\n",
    "    print(f\"Encoder Norm: {flops_breakdown['encoder_norm']:,} FLOPs\")\n",
    "    \n",
    "    if 'output_projection' in flops_breakdown:\n",
    "        print(f\"Output Projection: {flops_breakdown['output_projection']:,} FLOPs\")\n",
    "    if 'output_activation' in flops_breakdown:\n",
    "        print(f\"Output Activation: {flops_breakdown['output_activation']:,} FLOPs\")\n",
    "    \n",
    "    print(f\"\\n=== ENCODER ===\")\n",
    "    print(f\"Per Encoder Layer FLOPs: {flops_breakdown['encoder_layers']['total_per_layer']:,}\")\n",
    "    print(f\"Total Encoder Layers FLOPs: {flops_breakdown['total_encoder_layers']:,}\")\n",
    "    \n",
    "    print(f\"\\n--- Encoder Layer Breakdown ---\")\n",
    "    encoder_attention_total = sum(flops_breakdown['encoder_layers']['attention'].values())\n",
    "    encoder_ff_total = sum(flops_breakdown['encoder_layers']['feedforward'].values())\n",
    "    encoder_layer_total = flops_breakdown['encoder_layers']['total_per_layer']\n",
    "    \n",
    "    print(f\"Multi-Head Attention (on Variables): {encoder_attention_total:,} FLOPs ({encoder_attention_total/encoder_layer_total*100:.1f}%)\")\n",
    "    print(f\"Feed Forward Network: {encoder_ff_total:,} FLOPs ({encoder_ff_total/encoder_layer_total*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n--- Detailed Attention Breakdown ---\")\n",
    "    for component, flops in flops_breakdown['encoder_layers']['attention'].items():\n",
    "        print(f\"  {component}: {flops:,} FLOPs\")\n",
    "    \n",
    "    print(f\"\\n--- Detailed Feed Forward Breakdown ---\")\n",
    "    for component, flops in flops_breakdown['encoder_layers']['feedforward'].items():\n",
    "        print(f\"  {component}: {flops:,} FLOPs\")\n",
    "    \n",
    "    print(\"\\n--- iTransformer Specifics ---\")\n",
    "    print(\"• Attention operates on VARIABLES (not time steps)\")\n",
    "    print(\"• Input is inverted: [B, L, N] -> [B, N, L] -> [B, N, d_model]\")\n",
    "    print(\"• Each variable attends to all other variables\")\n",
    "    print(\"• Complexity: O(N²) instead of O(L²)\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"TOTAL FLOPs: {total_flops:,}\")\n",
    "    print(f\"TOTAL GFLOPs: {total_flops / 1e9:.3f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Test du modèle iTransformer\n",
    "from models.iTransformer import Model as iTransformer\n",
    "\n",
    "# Configuration pour le modèle iTransformer\n",
    "conf_itransformer = {\n",
    "    'task_name': 'anomaly_detection',\n",
    "    'seq_len': 96,\n",
    "    'pred_len': 96,\n",
    "    'enc_in': 10,        # Features d'entrée (nombre de variables)\n",
    "    'c_out': 10,         # Features de sortie\n",
    "    'num_class': 10,     # Nombre de classes pour classification\n",
    "    'd_model': 256,       # Dimension du modèle\n",
    "    'n_heads': 8,        # Nombre de têtes d'attention\n",
    "    'd_ff': 512,         # Dimension feedforward\n",
    "    'e_layers': 2,       # Nombre de couches encoder\n",
    "    'factor': 3,         # Facteur pour attention\n",
    "    'dropout': 0.1,\n",
    "    'activation': 'gelu',\n",
    "    'embed': 'timeF',\n",
    "    'freq': 'h'\n",
    "}\n",
    "configs_itransformer = type('Config', (), conf_itransformer)()\n",
    "\n",
    "# Créer le modèle iTransformer\n",
    "model_itransformer = iTransformer(configs_itransformer)\n",
    "print(\"Model parameters:\", sum(p.numel() for p in model_itransformer.parameters()))\n",
    "\n",
    "# Test des FLOPs\n",
    "batch_size = 32\n",
    "sequence_length = 96\n",
    "\n",
    "flops_breakdown, total_flops = count_flops_itransformer(\n",
    "    model_itransformer, batch_size=batch_size, sequence_length=sequence_length, configs=conf_itransformer\n",
    ")\n",
    "\n",
    "# Afficher les résultats\n",
    "print_flops_breakdown_itransformer(flops_breakdown, total_flops)\n",
    "\n",
    "# Test avec différentes longueurs de séquence\n",
    "print(f\"\\n=== TEST AVEC DIFFÉRENTES LONGUEURS DE SÉQUENCE ===\")\n",
    "flops_itransformer = []\n",
    "\n",
    "for seq_len in SEQ_LENGTHS:\n",
    "    # Ajuster la configuration pour chaque longueur de séquence\n",
    "    conf_test = conf_itransformer.copy()\n",
    "    conf_test['seq_len'] = seq_len\n",
    "    \n",
    "    flops_breakdown, total_flops = count_flops_itransformer(\n",
    "        model_itransformer, batch_size=10, sequence_length=seq_len, configs=conf_test\n",
    "    )\n",
    "    print(f\"Sequence Length: {seq_len:4d}, Total FLOPs: {total_flops:12,}, GFLOPs: {total_flops/1e9:8.3f}\")\n",
    "    flops_itransformer.append(total_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fceab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_flops_patchtst(model, batch_size=1, sequence_length=1, configs={}):\n",
    "    \"\"\"\n",
    "    Compte les FLOPs (Floating Point Operations) pour le modèle PatchTST.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Instance du modèle PatchTST\n",
    "    - batch_size: Taille du batch\n",
    "    - sequence_length: Longueur de la séquence\n",
    "    - configs: Configuration du modèle (dict)\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionnaire détaillé des FLOPs par composant\n",
    "    - int: Total des FLOPs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Paramètres du modèle\n",
    "    B = batch_size\n",
    "    L = sequence_length  # Sequence length\n",
    "    \n",
    "    # Récupérer les paramètres depuis la configuration\n",
    "    d_model = configs.get('d_model')  # Dimension du modèle\n",
    "    n_heads = configs.get('n_heads')  # Nombre de têtes d'attention\n",
    "    d_ff = configs.get('d_ff')  # Dimension feedforward\n",
    "    e_layers = configs.get('e_layers')  # Nombre de couches encoder\n",
    "    patch_len = configs.get('patch_len', 16)  # Longueur des patches\n",
    "    stride = configs.get('stride', 8)  # Stride pour les patches\n",
    "    \n",
    "    # Input/Output dimensions\n",
    "    N = configs.get('enc_in')  # Number of variables (features)\n",
    "    \n",
    "    # Calcul du nombre de patches\n",
    "    padding = stride\n",
    "    patch_num = int((L - patch_len) / stride + 1)\n",
    "    if padding:\n",
    "        patch_num += 1\n",
    "    \n",
    "    # Output dimension selon la tâche\n",
    "    if configs.get('task_name') == 'classification':\n",
    "        O = configs.get('num_class')\n",
    "    elif configs.get('task_name') in ['long_term_forecast', 'short_term_forecast']:\n",
    "        O = configs.get('pred_len')\n",
    "    else:  # imputation, anomaly_detection\n",
    "        O = L  # seq_len\n",
    "    \n",
    "    # Dimension par tête d'attention\n",
    "    head_dim = d_model // n_heads\n",
    "    \n",
    "    flops_breakdown = {}\n",
    "    \n",
    "    # ==================== NORMALIZATION ====================\n",
    "    \n",
    "    normalization_flops = 0\n",
    "    if configs.get('task_name') in ['long_term_forecast', 'short_term_forecast', 'anomaly_detection', 'classification']:\n",
    "        # Mean computation: [B, L, N] -> [B, 1, N]\n",
    "        normalization_flops += B * L * N  # sum\n",
    "        normalization_flops += B * N      # divide par L\n",
    "        \n",
    "        # Variance computation: [B, L, N]\n",
    "        normalization_flops += B * L * N  # subtract mean\n",
    "        normalization_flops += B * L * N  # square\n",
    "        normalization_flops += B * L * N  # sum\n",
    "        normalization_flops += B * N      # divide par L\n",
    "        normalization_flops += B * N      # sqrt\n",
    "        \n",
    "        # Normalization: [B, L, N]\n",
    "        normalization_flops += B * L * N  # subtract mean\n",
    "        normalization_flops += B * L * N  # divide by std\n",
    "        \n",
    "        # Denormalization (en sortie)\n",
    "        if configs.get('task_name') in ['long_term_forecast', 'short_term_forecast']:\n",
    "            pred_len = configs.get('pred_len', L)\n",
    "            normalization_flops += B * pred_len * N * 2  # multiply + add\n",
    "        else:\n",
    "            normalization_flops += B * L * N * 2  # multiply + add\n",
    "    \n",
    "    elif configs.get('task_name') == 'imputation':\n",
    "        # Imputation has special normalization with mask\n",
    "        # Approximation similaire mais avec masking\n",
    "        normalization_flops += B * L * N * 10  # Approximation pour toutes les opérations de masking\n",
    "    \n",
    "    # ==================== PATCH EMBEDDING ====================\n",
    "    \n",
    "    patch_embedding_flops = {}\n",
    "    \n",
    "    # Input shape après permutation: [B, N, L] -> [B*N, L]\n",
    "    # Unfold operation pour créer les patches\n",
    "    # Unfold: [B*N, L] -> [B*N, patch_num, patch_len]\n",
    "    # Approximation: coût de l'extraction des patches\n",
    "    patch_embedding_flops['unfold_patches'] = B * N * patch_num * patch_len\n",
    "    \n",
    "    # Linear projection: [B*N, patch_num, patch_len] @ [patch_len, d_model] -> [B*N, patch_num, d_model]\n",
    "    patch_embedding_flops['value_embedding'] = B * N * patch_num * patch_len * d_model\n",
    "    \n",
    "    # Positional embedding (learnable)\n",
    "    # Addition [B*N, patch_num, d_model] + [patch_num, d_model]\n",
    "    # Pas de FLOPs pour l'addition, juste accès mémoire\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # ==================== ENCODER LAYERS ====================\n",
    "    \n",
    "    encoder_layer_flops = {}\n",
    "    \n",
    "    # ==================== MULTI-HEAD ATTENTION ====================\n",
    "    \n",
    "    attention_flops = {}\n",
    "    \n",
    "    # Input shape: [B*N, patch_num, d_model]\n",
    "    # Query, Key, Value projections\n",
    "    attention_flops['Q_projection'] = B * N * patch_num * d_model * d_model\n",
    "    attention_flops['K_projection'] = B * N * patch_num * d_model * d_model\n",
    "    attention_flops['V_projection'] = B * N * patch_num * d_model * d_model\n",
    "    \n",
    "    # Reshape pour multi-head: [B*N, patch_num, d_model] -> [B*N, n_heads, patch_num, head_dim]\n",
    "    # Pas de FLOPs, juste un reshape\n",
    "    \n",
    "    # Attention scores: Q @ K^T\n",
    "    # Q: [B*N, n_heads, patch_num, head_dim], K^T: [B*N, n_heads, head_dim, patch_num] -> [B*N, n_heads, patch_num, patch_num]\n",
    "    attention_flops['attention_scores'] = B * N * n_heads * patch_num * head_dim * patch_num\n",
    "    \n",
    "    # Scale by sqrt(head_dim)\n",
    "    attention_flops['scale_attention'] = B * N * n_heads * patch_num * patch_num\n",
    "    \n",
    "    # Softmax sur la dimension des clés (patch_num)\n",
    "    # Approximation: exp + sum + divide = 3 opérations par élément\n",
    "    attention_flops['attention_softmax'] = B * N * n_heads * patch_num * patch_num * 3\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # Attention weights @ V: [B*N, n_heads, patch_num, patch_num] @ [B*N, n_heads, patch_num, head_dim] -> [B*N, n_heads, patch_num, head_dim]\n",
    "    attention_flops['attention_values'] = B * N * n_heads * patch_num * patch_num * head_dim\n",
    "    \n",
    "    # Concatenate heads: [B*N, n_heads, patch_num, head_dim] -> [B*N, patch_num, d_model]\n",
    "    # Pas de FLOPs, juste un reshape\n",
    "    \n",
    "    # Output projection: [B*N, patch_num, d_model] @ [d_model, d_model] -> [B*N, patch_num, d_model]\n",
    "    attention_flops['output_projection'] = B * N * patch_num * d_model * d_model\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # Residual connection + LayerNorm1\n",
    "    attention_flops['residual_add'] = B * N * patch_num * d_model\n",
    "    attention_flops['layer_norm1'] = B * N * patch_num * d_model * 3  # mean, var, normalize\n",
    "    \n",
    "    # ==================== FEED FORWARD NETWORK ====================\n",
    "    \n",
    "    feedforward_flops = {}\n",
    "    \n",
    "    # Linear 1: [B*N, patch_num, d_model] -> [B*N, patch_num, d_ff]\n",
    "    feedforward_flops['linear1'] = B * N * patch_num * d_model * d_ff\n",
    "    \n",
    "    # Activation (GELU)\n",
    "    # Approximation: 2 opérations par élément pour GELU\n",
    "    feedforward_flops['activation'] = B * N * patch_num * d_ff * 2\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # Linear 2: [B*N, patch_num, d_ff] -> [B*N, patch_num, d_model]\n",
    "    feedforward_flops['linear2'] = B * N * patch_num * d_ff * d_model\n",
    "    \n",
    "    # Dropout (pas de FLOPs)\n",
    "    \n",
    "    # Residual connection + LayerNorm2\n",
    "    feedforward_flops['residual_add'] = B * N * patch_num * d_model\n",
    "    feedforward_flops['layer_norm2'] = B * N * patch_num * d_model * 3\n",
    "    \n",
    "    # ==================== ASSEMBLY ENCODER LAYER FLOPS ====================\n",
    "    \n",
    "    encoder_layer_total = sum(attention_flops.values()) + sum(feedforward_flops.values())\n",
    "    \n",
    "    encoder_layer_flops['attention'] = attention_flops\n",
    "    encoder_layer_flops['feedforward'] = feedforward_flops\n",
    "    encoder_layer_flops['total_per_layer'] = encoder_layer_total\n",
    "    \n",
    "    # ==================== FINAL ENCODER NORMALIZATION ====================\n",
    "    \n",
    "    # BatchNorm1d avec transpose\n",
    "    # Transpose: [B*N, patch_num, d_model] -> [B*N, d_model, patch_num] (pas de FLOPs)\n",
    "    # BatchNorm1d: [B*N, d_model, patch_num] (3 ops par élément: mean, var, normalize)\n",
    "    encoder_norm_flops = B * N * d_model * patch_num * 3\n",
    "    # Transpose retour: [B*N, d_model, patch_num] -> [B*N, patch_num, d_model] (pas de FLOPs)\n",
    "    \n",
    "    # ==================== RESHAPE ET PERMUTE ====================\n",
    "    \n",
    "    reshape_flops = {}\n",
    "    \n",
    "    # Reshape: [B*N, patch_num, d_model] -> [B, N, patch_num, d_model] (pas de FLOPs)\n",
    "    # Permute: [B, N, patch_num, d_model] -> [B, N, d_model, patch_num] (pas de FLOPs)\n",
    "    reshape_flops['reshapes_permutes'] = 0  # Pas de FLOPs computationnels\n",
    "    \n",
    "    # ==================== HEAD/OUTPUT PROJECTION ====================\n",
    "    \n",
    "    head_flops = {}\n",
    "    \n",
    "    # head_nf calculation\n",
    "    head_nf = d_model * patch_num\n",
    "    \n",
    "    if configs.get('task_name') == 'classification':\n",
    "        # Flatten: [B, N, d_model, patch_num] -> [B, N * d_model * patch_num] (pas de FLOPs)\n",
    "        head_flops['flatten'] = 0\n",
    "        \n",
    "        # Dropout (pas de FLOPs)\n",
    "        \n",
    "        # Projection: [B, N * d_model * patch_num] @ [N * d_model * patch_num, num_class] -> [B, num_class]\n",
    "        head_flops['classification_projection'] = B * (N * head_nf) * O\n",
    "        \n",
    "    else:\n",
    "        # FlattenHead pour autres tâches\n",
    "        # Flatten: [B, N, d_model, patch_num] -> [B, N, d_model * patch_num] (pas de FLOPs)\n",
    "        head_flops['flatten'] = 0\n",
    "        \n",
    "        # Linear: [B, N, head_nf] @ [head_nf, target_window] -> [B, N, target_window]\n",
    "        head_flops['linear_projection'] = B * N * head_nf * O\n",
    "        \n",
    "        # Dropout (pas de FLOPs)\n",
    "        \n",
    "        # Permute final: [B, N, target_window] -> [B, target_window, N] (pas de FLOPs)\n",
    "    \n",
    "    # ==================== TOTAL CALCULATION ====================\n",
    "    \n",
    "    flops_breakdown['normalization'] = normalization_flops\n",
    "    flops_breakdown['patch_embedding'] = sum(patch_embedding_flops.values())\n",
    "    flops_breakdown['encoder_layers'] = encoder_layer_flops\n",
    "    flops_breakdown['total_encoder_layers'] = encoder_layer_total * e_layers\n",
    "    flops_breakdown['encoder_norm'] = encoder_norm_flops\n",
    "    flops_breakdown['reshape_permute'] = sum(reshape_flops.values())\n",
    "    flops_breakdown['head'] = sum(head_flops.values())\n",
    "    \n",
    "    # Détails pour debug\n",
    "    flops_breakdown['patch_embedding_detail'] = patch_embedding_flops\n",
    "    flops_breakdown['head_detail'] = head_flops\n",
    "    \n",
    "    total_flops = (flops_breakdown['normalization'] +\n",
    "                  flops_breakdown['patch_embedding'] + \n",
    "                  flops_breakdown['total_encoder_layers'] + \n",
    "                  flops_breakdown['encoder_norm'] +\n",
    "                  flops_breakdown['reshape_permute'] +\n",
    "                  flops_breakdown['head'])\n",
    "    \n",
    "    flops_breakdown['total'] = total_flops\n",
    "    \n",
    "    # Informations supplémentaires pour debug\n",
    "    flops_breakdown['debug_info'] = {\n",
    "        'patch_num': patch_num,\n",
    "        'head_nf': head_nf,\n",
    "        'variables': N,\n",
    "        'patch_len': patch_len,\n",
    "        'stride': stride\n",
    "    }\n",
    "    \n",
    "    return flops_breakdown, total_flops\n",
    "\n",
    "def print_flops_breakdown_patchtst(flops_breakdown, total_flops):\n",
    "    \"\"\"\n",
    "    Affiche un résumé détaillé des FLOPs pour le modèle PatchTST.\n",
    "    \n",
    "    Parameters:\n",
    "    - flops_breakdown: Dictionnaire des FLOPs par composant\n",
    "    - total_flops: Total des FLOPs\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(f\"PATCHTST - FLOPs BREAKDOWN\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    debug_info = flops_breakdown['debug_info']\n",
    "    print(f\"Patch Configuration:\")\n",
    "    print(f\"  Variables: {debug_info['variables']}\")\n",
    "    print(f\"  Patch Length: {debug_info['patch_len']}\")\n",
    "    print(f\"  Stride: {debug_info['stride']}\")\n",
    "    print(f\"  Number of Patches: {debug_info['patch_num']}\")\n",
    "    print(f\"  Head Features: {debug_info['head_nf']}\")\n",
    "    \n",
    "    print(f\"\\nFLOPs Breakdown:\")\n",
    "    print(f\"Normalization: {flops_breakdown['normalization']:,} FLOPs\")\n",
    "    print(f\"Patch Embedding: {flops_breakdown['patch_embedding']:,} FLOPs\")\n",
    "    print(f\"Encoder Norm: {flops_breakdown['encoder_norm']:,} FLOPs\")\n",
    "    print(f\"Reshape/Permute: {flops_breakdown['reshape_permute']:,} FLOPs\")\n",
    "    print(f\"Head/Output: {flops_breakdown['head']:,} FLOPs\")\n",
    "    \n",
    "    print(f\"\\n=== ENCODER ===\")\n",
    "    print(f\"Per Encoder Layer FLOPs: {flops_breakdown['encoder_layers']['total_per_layer']:,}\")\n",
    "    print(f\"Total Encoder Layers FLOPs: {flops_breakdown['total_encoder_layers']:,}\")\n",
    "    \n",
    "    print(f\"\\n--- Encoder Layer Breakdown ---\")\n",
    "    encoder_attention_total = sum(flops_breakdown['encoder_layers']['attention'].values())\n",
    "    encoder_ff_total = sum(flops_breakdown['encoder_layers']['feedforward'].values())\n",
    "    encoder_layer_total = flops_breakdown['encoder_layers']['total_per_layer']\n",
    "    \n",
    "    print(f\"Multi-Head Attention (on Patches): {encoder_attention_total:,} FLOPs ({encoder_attention_total/encoder_layer_total*100:.1f}%)\")\n",
    "    print(f\"Feed Forward Network: {encoder_ff_total:,} FLOPs ({encoder_ff_total/encoder_layer_total*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n--- Detailed Patch Embedding Breakdown ---\")\n",
    "    for component, flops in flops_breakdown['patch_embedding_detail'].items():\n",
    "        print(f\"  {component}: {flops:,} FLOPs\")\n",
    "    \n",
    "    print(f\"\\n--- Detailed Attention Breakdown ---\")\n",
    "    for component, flops in flops_breakdown['encoder_layers']['attention'].items():\n",
    "        print(f\"  {component}: {flops:,} FLOPs\")\n",
    "    \n",
    "    print(f\"\\n--- Detailed Head Breakdown ---\")\n",
    "    for component, flops in flops_breakdown['head_detail'].items():\n",
    "        print(f\"  {component}: {flops:,} FLOPs\")\n",
    "    \n",
    "    print(\"\\n--- PatchTST Specifics ---\")\n",
    "    print(\"• Input is segmented into patches\")\n",
    "    print(\"• Each variable processed independently\")\n",
    "    print(\"• Attention operates on PATCHES (not time steps)\")\n",
    "    print(f\"• Complexity: O(P²) where P = {debug_info['patch_num']} patches\")\n",
    "    print(\"• Channel Independence: each variable has separate attention\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"TOTAL FLOPs: {total_flops:,}\")\n",
    "    print(f\"TOTAL GFLOPs: {total_flops / 1e9:.3f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Test du modèle PatchTST\n",
    "from models.PatchTST import Model as PatchTST\n",
    "\n",
    "# Configuration pour le modèle PatchTST\n",
    "conf_patchtst = {\n",
    "    'task_name': 'anomaly_detection',\n",
    "    'seq_len': 96,\n",
    "    'pred_len': 96,\n",
    "    'enc_in': 10,        # Features d'entrée (nombre de variables)\n",
    "    'c_out': 10,         # Features de sortie\n",
    "    'num_class': 10,     # Nombre de classes pour classification\n",
    "    'd_model': 256,       # Dimension du modèle\n",
    "    'n_heads': 8,        # Nombre de têtes d'attention\n",
    "    'd_ff': 256,         # Dimension feedforward\n",
    "    'e_layers': 2,       # Nombre de couches encoder\n",
    "    'factor': 3,         # Facteur pour attention\n",
    "    'patch_len': 16,     # Longueur des patches\n",
    "    'stride': 8,         # Stride pour les patches\n",
    "    'dropout': 0.1,\n",
    "    'activation': 'gelu',\n",
    "    'embed': 'timeF',\n",
    "    'freq': 'h'\n",
    "}\n",
    "configs_patchtst = type('Config', (), conf_patchtst)()\n",
    "\n",
    "# Créer le modèle PatchTST\n",
    "model_patchtst = PatchTST(configs_patchtst, \n",
    "                         patch_len=conf_patchtst['patch_len'],\n",
    "                         stride=conf_patchtst['stride'])\n",
    "print(\"Model parameters:\", sum(p.numel() for p in model_patchtst.parameters()))\n",
    "\n",
    "print(\"=== MODÈLE PATCHTST CRÉÉ ===\")\n",
    "print(f\"Task: {model_patchtst.task_name}\")\n",
    "print(f\"Sequence length: {model_patchtst.seq_len}\")\n",
    "if hasattr(model_patchtst, 'pred_len'):\n",
    "    print(f\"Prediction length: {model_patchtst.pred_len}\")\n",
    "print(f\"Encoder layers: {len(model_patchtst.encoder.attn_layers)}\")\n",
    "print(f\"Features (variables): {conf_patchtst['enc_in']}\")\n",
    "print(f\"Patch length: {conf_patchtst['patch_len']}\")\n",
    "print(f\"Stride: {conf_patchtst['stride']}\")\n",
    "\n",
    "# Calculer le nombre de patches pour info\n",
    "patch_num = int((conf_patchtst['seq_len'] - conf_patchtst['patch_len']) / conf_patchtst['stride'] + 1) + 1  # +1 pour padding\n",
    "print(f\"Number of patches: {patch_num}\")\n",
    "\n",
    "# Test des FLOPs\n",
    "batch_size = 32\n",
    "sequence_length = 96\n",
    "\n",
    "flops_breakdown, total_flops = count_flops_patchtst(\n",
    "    model_patchtst, batch_size=batch_size, sequence_length=sequence_length, configs=conf_patchtst\n",
    ")\n",
    "\n",
    "# Afficher les résultats\n",
    "print_flops_breakdown_patchtst(flops_breakdown, total_flops)\n",
    "\n",
    "# Test avec différentes longueurs de séquence\n",
    "print(f\"\\n=== TEST AVEC DIFFÉRENTES LONGUEURS DE SÉQUENCE ===\")\n",
    "flops_patchtst = []\n",
    "\n",
    "for seq_len in SEQ_LENGTHS:\n",
    "    # Ajuster la configuration pour chaque longueur de séquence\n",
    "    conf_test = conf_patchtst.copy()\n",
    "    conf_test['seq_len'] = seq_len\n",
    "    \n",
    "    flops_breakdown, total_flops = count_flops_patchtst(\n",
    "        model_patchtst, batch_size=10, sequence_length=seq_len, configs=conf_test\n",
    "    )\n",
    "    print(f\"Sequence Length: {seq_len:4d}, Total FLOPs: {total_flops:12,}, GFLOPs: {total_flops/1e9:8.3f}\")\n",
    "    flops_patchtst.append(total_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bd8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_flops_timesnet(model, batch_size=1, sequence_length=1, configs={}):\n",
    "    \"\"\"\n",
    "    Compte les FLOPs (Floating Point Operations) pour le modèle TimesNet.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Instance du modèle TimesNet\n",
    "    - batch_size: Taille du batch\n",
    "    - sequence_length: Longueur de la séquence\n",
    "    - configs: Configuration du modèle (dict)\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionnaire détaillé des FLOPs par composant\n",
    "    - int: Total des FLOPs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Paramètres du modèle\n",
    "    B = batch_size\n",
    "    L = sequence_length  # Sequence length\n",
    "    \n",
    "    # Récupérer les paramètres depuis la configuration\n",
    "    d_model = configs.get('d_model')  # Dimension du modèle\n",
    "    d_ff = configs.get('d_ff')  # Dimension feedforward (utilisée dans Inception blocks)\n",
    "    e_layers = configs.get('e_layers')  # Nombre de couches TimesBlock\n",
    "    top_k = configs.get('top_k', 5)  # Nombre de périodes top-k à analyser\n",
    "    num_kernels = configs.get('num_kernels', 6)  # Nombre de kernels dans Inception\n",
    "    \n",
    "    # Input/Output dimensions\n",
    "    I = configs.get('enc_in')  # Input features\n",
    "    O = configs.get('c_out')  # Output features\n",
    "    \n",
    "    # Dimensions pour forecasting\n",
    "    pred_len = configs.get('pred_len', 0)\n",
    "    \n",
    "    flops_breakdown = {}\n",
    "    \n",
    "    # ==================== NORMALIZATION (pour forecasting/imputation/anomaly) ====================\n",
    "    \n",
    "    normalization_flops = 0\n",
    "    if configs.get('task_name') in ['long_term_forecast', 'short_term_forecast']:\n",
    "        # Mean computation: [B, L, I]\n",
    "        normalization_flops += B * L * I  # sum\n",
    "        normalization_flops += B * I      # divide par L\n",
    "        \n",
    "        # Variance computation: [B, L, I]\n",
    "        normalization_flops += B * L * I  # subtract mean\n",
    "        normalization_flops += B * L * I  # square + sqrt\n",
    "        normalization_flops += B * L * I  # sum\n",
    "        normalization_flops += B * I      # divide par L + sqrt\n",
    "        \n",
    "        # Normalization: [B, L, I]\n",
    "        normalization_flops += B * L * I  # subtract mean\n",
    "        normalization_flops += B * L * I  # divide by std\n",
    "        \n",
    "        # Denormalization (en sortie)\n",
    "        normalization_flops += B * (L + pred_len) * I * 2  # multiply + add\n",
    "        \n",
    "    elif configs.get('task_name') == 'imputation':\n",
    "        # Imputation avec masking (approximation)\n",
    "        normalization_flops += B * L * I * 10  # Diverses opérations avec masques\n",
    "        \n",
    "    elif configs.get('task_name') == 'anomaly_detection':\n",
    "        # Normalization similaire mais sans denormalization\n",
    "        normalization_flops += B * L * I * 7  # mean, var, sqrt, normalize\n",
    "    \n",
    "    # ==================== INPUT EMBEDDING ====================\n",
    "    \n",
    "    # DataEmbedding: value embedding + temporal embedding\n",
    "    # Value embedding: Linear [I -> d_model]\n",
    "    flops_breakdown['input_embedding'] = B * L * I * d_model\n",
    "    \n",
    "    # Temporal embedding (approximation)\n",
    "    flops_breakdown['temporal_embedding'] = B * L * 4 * d_model  # 4 features temporelles typiques\n",
    "    \n",
    "    # ==================== PREDICT LINEAR (pour forecasting) ====================\n",
    "    \n",
    "    predict_linear_flops = 0\n",
    "    if configs.get('task_name') in ['long_term_forecast', 'short_term_forecast']:\n",
    "        # predict_linear: permute + linear + permute\n",
    "        # [B, L, d_model] -> [B, d_model, L] -> [B, d_model, L+pred_len] -> [B, L+pred_len, d_model]\n",
    "        predict_linear_flops = B * d_model * L * (L + pred_len)\n",
    "    \n",
    "    # ==================== TIMESBLOCK LAYERS ====================\n",
    "    \n",
    "    timesblock_layer_flops = {}\n",
    "    \n",
    "    # ==================== FFT FOR PERIOD DETECTION ====================\n",
    "    \n",
    "    fft_flops = {}\n",
    "    \n",
    "    # FFT computation: [B, L, I] -> complexe\n",
    "    # FFT: O(L log L) per feature per batch\n",
    "    fft_flops['rfft'] = B * I * L * math.log2(L) * 2  # complexe FFT\n",
    "    \n",
    "    # Amplitude computation: abs(xf)\n",
    "    fft_flops['amplitude'] = B * I * (L // 2 + 1)  # rfft donne (L//2 + 1) fréquences\n",
    "    \n",
    "    # Mean over features and find top-k\n",
    "    fft_flops['mean_topk'] = B * (L // 2 + 1) * I + B * (L // 2 + 1) * math.log2(top_k)\n",
    "    \n",
    "    # Period calculation (division)\n",
    "    fft_flops['period_calc'] = top_k\n",
    "    \n",
    "    # ==================== TIMESBLOCK PROCESSING ====================\n",
    "    \n",
    "    timesblock_processing_flops = {}\n",
    "    \n",
    "    # Pour chaque période dans top_k\n",
    "    for k in range(top_k):\n",
    "        period_flops = {}\n",
    "        \n",
    "        # Estimation de la période moyenne (heuristique)\n",
    "        avg_period = max(L // (2 + k), 1)  # Période décroissante\n",
    "\n",
    "        # Padding computation (si nécessaire)\n",
    "        # Approximation: dans la plupart des cas il y a du padding\n",
    "        length = ((L + pred_len) // avg_period + 1) * avg_period\n",
    "        padding_length = length - (L + pred_len)\n",
    "        period_flops['padding'] = B * padding_length * I if padding_length > 0 else 0\n",
    "        \n",
    "        # Reshape vers 2D: [B, length//period, period, I] -> [B, I, length//period, period]\n",
    "        # Pas de FLOPs, juste reshape et permute\n",
    "        \n",
    "        # Dimensions après reshape\n",
    "        H = length // avg_period  # hauteur\n",
    "        W = avg_period            # largeur\n",
    "        \n",
    "        # ==================== INCEPTION BLOCK V1 (2 blocs en séquence) ====================\n",
    "        \n",
    "        inception_flops = {}\n",
    "        \n",
    "        # Premier Inception Block: [B, I, H, W] -> [B, d_ff, H, W]\n",
    "        # Approximation des conv2d dans Inception (plusieurs kernel sizes)\n",
    "        \n",
    "        # 1x1 conv branch\n",
    "        inception_flops['conv1x1_1'] = B * H * W * d_model * d_ff\n",
    "        \n",
    "        # 1x1 -> 3x3 conv branch  \n",
    "        inception_flops['conv1x1_to_3x3'] = B * H * W * d_model * (d_ff // 4)  # reduction\n",
    "        inception_flops['conv3x3'] = B * H * W * (d_ff // 4) * (d_ff // 4) * 9  # 3x3 kernel\n",
    "        \n",
    "        # 1x1 -> 5x5 conv branch\n",
    "        inception_flops['conv1x1_to_5x5'] = B * H * W * d_model * (d_ff // 8)  # reduction\n",
    "        inception_flops['conv5x5'] = B * H * W * (d_ff // 8) * (d_ff // 8) * 25  # 5x5 kernel\n",
    "        \n",
    "        # MaxPool -> 1x1 conv branch\n",
    "        inception_flops['maxpool'] = B * H * W * d_model * 9  # 3x3 maxpool approximation\n",
    "        inception_flops['conv1x1_after_pool'] = B * H * W * d_model * (d_ff // 4)\n",
    "        \n",
    "        # Concatenation (pas de FLOPs)\n",
    "        \n",
    "        # GELU activation\n",
    "        inception_flops['gelu'] = B * H * W * d_ff * 2\n",
    "        \n",
    "        # Deuxième Inception Block: [B, d_ff, H, W] -> [B, d_model, H, W]\n",
    "        # Structure similaire mais d_ff -> d_model\n",
    "        inception_flops['conv1x1_2'] = B * H * W * d_ff * d_model\n",
    "        inception_flops['conv1x1_to_3x3_2'] = B * H * W * d_ff * (d_model // 4)\n",
    "        inception_flops['conv3x3_2'] = B * H * W * (d_model // 4) * (d_model // 4) * 9\n",
    "        inception_flops['conv1x1_to_5x5_2'] = B * H * W * d_ff * (d_model // 8)\n",
    "        inception_flops['conv5x5_2'] = B * H * W * (d_model // 8) * (d_model // 8) * 25\n",
    "        inception_flops['maxpool_2'] = B * H * W * d_ff * 9\n",
    "        inception_flops['conv1x1_after_pool_2'] = B * H * W * d_ff * (d_model // 4)\n",
    "        \n",
    "        # Reshape back: [B, d_model, H, W] -> [B, length, I]\n",
    "        # Pas de FLOPs, juste permute et reshape\n",
    "        \n",
    "        # Crop to original length\n",
    "        period_flops['inception'] = sum(inception_flops.values())\n",
    "        \n",
    "        timesblock_processing_flops[f'period_{k}'] = period_flops\n",
    "    \n",
    "    # ==================== ADAPTIVE AGGREGATION ====================\n",
    "    \n",
    "    aggregation_flops = {}\n",
    "    \n",
    "    # Softmax sur les poids de période: [B, top_k] -> [B, top_k]\n",
    "    aggregation_flops['period_softmax'] = B * top_k * 3  # exp + sum + div\n",
    "    \n",
    "    # Reshape weights: [B, top_k] -> [B, L, I, top_k]\n",
    "    # Pas de FLOPs, juste broadcast\n",
    "    \n",
    "    # Weighted sum: [B, L, I, top_k] -> [B, L, I]\n",
    "    aggregation_flops['weighted_sum'] = B * L * I * top_k\n",
    "    \n",
    "    # Residual connection: res + x\n",
    "    aggregation_flops['residual_add'] = B * L * I\n",
    "    \n",
    "    # ==================== LAYER NORMALIZATION ====================\n",
    "    \n",
    "    layer_norm_flops = {}\n",
    "    \n",
    "    # LayerNorm après chaque TimesBlock: [B, L, d_model]\n",
    "    layer_norm_flops['layer_norm'] = B * L * d_model * 3  # mean, var, normalize\n",
    "    \n",
    "    # ==================== ASSEMBLY TIMESBLOCK LAYER FLOPS ====================\n",
    "    \n",
    "    # Total des FLOPs pour un TimesBlock\n",
    "    timesblock_layer_total = (sum(fft_flops.values()) + \n",
    "                             sum([sum(period_flops.values()) for period_flops in timesblock_processing_flops.values()]) +\n",
    "                             sum(aggregation_flops.values()) + \n",
    "                             sum(layer_norm_flops.values()))\n",
    "    \n",
    "    timesblock_layer_flops['fft_period_detection'] = fft_flops\n",
    "    timesblock_layer_flops['period_processing'] = timesblock_processing_flops\n",
    "    timesblock_layer_flops['adaptive_aggregation'] = aggregation_flops\n",
    "    timesblock_layer_flops['layer_norm'] = layer_norm_flops\n",
    "    timesblock_layer_flops['total_per_layer'] = timesblock_layer_total\n",
    "    \n",
    "    # ==================== OUTPUT PROJECTION ====================\n",
    "    \n",
    "    output_flops = 0\n",
    "    \n",
    "    if configs.get('task_name') == 'classification':\n",
    "        # GELU activation: [B, L, d_model]\n",
    "        gelu_flops = B * L * d_model * 2\n",
    "        # Dropout (pas de FLOPs)\n",
    "        # Reshape: [B, L * d_model]\n",
    "        # Projection: [B, L * d_model] @ [L * d_model, num_class] -> [B, num_class]\n",
    "        num_class = configs.get('num_class', O)\n",
    "        projection_flops = B * (L * d_model) * num_class\n",
    "        \n",
    "        output_flops = gelu_flops + projection_flops\n",
    "        flops_breakdown['output_activation'] = gelu_flops\n",
    "        flops_breakdown['output_projection'] = projection_flops\n",
    "        \n",
    "    elif configs.get('task_name') in ['long_term_forecast', 'short_term_forecast']:\n",
    "        # Projection: [B, L+pred_len, d_model] @ [d_model, O] -> [B, L+pred_len, O]\n",
    "        output_flops = B * (L + pred_len) * d_model * O\n",
    "        flops_breakdown['output_projection'] = output_flops\n",
    "        \n",
    "    elif configs.get('task_name') in ['imputation', 'anomaly_detection']:\n",
    "        # Direct projection: [B, L, d_model] @ [d_model, O] -> [B, L, O]\n",
    "        output_flops = B * L * d_model * O\n",
    "        flops_breakdown['output_projection'] = output_flops\n",
    "    \n",
    "    # ==================== TOTAL CALCULATION ====================\n",
    "    \n",
    "    flops_breakdown['normalization'] = normalization_flops\n",
    "    flops_breakdown['input_embedding'] = flops_breakdown['input_embedding']\n",
    "    flops_breakdown['temporal_embedding'] = flops_breakdown['temporal_embedding']\n",
    "    flops_breakdown['predict_linear'] = predict_linear_flops\n",
    "    flops_breakdown['timesblock_layers'] = timesblock_layer_flops\n",
    "    flops_breakdown['total_timesblock_layers'] = timesblock_layer_total * e_layers\n",
    "    \n",
    "    total_flops = (flops_breakdown['normalization'] +\n",
    "                  flops_breakdown['input_embedding'] + \n",
    "                  flops_breakdown['temporal_embedding'] +\n",
    "                  flops_breakdown['predict_linear'] +\n",
    "                  flops_breakdown['total_timesblock_layers'] + \n",
    "                  output_flops)\n",
    "    \n",
    "    flops_breakdown['total'] = total_flops\n",
    "    \n",
    "    return flops_breakdown, total_flops\n",
    "\n",
    "def print_flops_breakdown_timesnet(flops_breakdown, total_flops):\n",
    "    \"\"\"\n",
    "    Affiche un résumé détaillé des FLOPs pour le modèle TimesNet.\n",
    "    \n",
    "    Parameters:\n",
    "    - flops_breakdown: Dictionnaire des FLOPs par composant\n",
    "    - total_flops: Total des FLOPs\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(f\"TIMESNET - FLOPs BREAKDOWN\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if flops_breakdown['normalization'] > 0:\n",
    "        print(f\"Normalization: {flops_breakdown['normalization']:,} FLOPs\")\n",
    "    print(f\"Input Embedding: {flops_breakdown['input_embedding']:,} FLOPs\")\n",
    "    print(f\"Temporal Embedding: {flops_breakdown['temporal_embedding']:,} FLOPs\")\n",
    "    if flops_breakdown['predict_linear'] > 0:\n",
    "        print(f\"Predict Linear: {flops_breakdown['predict_linear']:,} FLOPs\")\n",
    "    \n",
    "    if 'output_projection' in flops_breakdown:\n",
    "        print(f\"Output Projection: {flops_breakdown['output_projection']:,} FLOPs\")\n",
    "    if 'output_activation' in flops_breakdown:\n",
    "        print(f\"Output Activation: {flops_breakdown['output_activation']:,} FLOPs\")\n",
    "    \n",
    "    print(f\"\\n=== TIMESBLOCK LAYERS ===\")\n",
    "    print(f\"Per TimesBlock Layer FLOPs: {flops_breakdown['timesblock_layers']['total_per_layer']:,}\")\n",
    "    print(f\"Total TimesBlock Layers FLOPs: {flops_breakdown['total_timesblock_layers']:,}\")\n",
    "    \n",
    "    print(f\"\\n--- TimesBlock Layer Breakdown ---\")\n",
    "    fft_total = sum(flops_breakdown['timesblock_layers']['fft_period_detection'].values())\n",
    "    processing_total = sum([sum(period_flops.values()) for period_flops in flops_breakdown['timesblock_layers']['period_processing'].values()])\n",
    "    aggregation_total = sum(flops_breakdown['timesblock_layers']['adaptive_aggregation'].values())\n",
    "    norm_total = sum(flops_breakdown['timesblock_layers']['layer_norm'].values())\n",
    "    \n",
    "    layer_total = flops_breakdown['timesblock_layers']['total_per_layer']\n",
    "    print(f\"FFT Period Detection: {fft_total:,} FLOPs ({fft_total/layer_total*100:.1f}%)\")\n",
    "    print(f\"Period Processing (Inception): {processing_total:,} FLOPs ({processing_total/layer_total*100:.1f}%)\")\n",
    "    print(f\"Adaptive Aggregation: {aggregation_total:,} FLOPs ({aggregation_total/layer_total*100:.1f}%)\")\n",
    "    print(f\"Layer Normalization: {norm_total:,} FLOPs ({norm_total/layer_total*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n--- Detailed FFT Breakdown ---\")\n",
    "    for component, flops in flops_breakdown['timesblock_layers']['fft_period_detection'].items():\n",
    "        print(f\"  {component}: {flops:,} FLOPs\")\n",
    "    \n",
    "    print(f\"\\n--- Detailed Aggregation Breakdown ---\")\n",
    "    for component, flops in flops_breakdown['timesblock_layers']['adaptive_aggregation'].items():\n",
    "        print(f\"  {component}: {flops:,} FLOPs\")\n",
    "    \n",
    "    print(\"\\n--- TimesNet Specifics ---\")\n",
    "    print(\"• Uses FFT for period detection in time series\")\n",
    "    print(\"• Transforms 1D time series to 2D representation\")\n",
    "    print(\"• Applies 2D Inception blocks for feature extraction\")\n",
    "    print(\"• Adaptively aggregates multiple period representations\")\n",
    "    print(\"• Complexity dominated by FFT: O(L log L) and Inception: O(H*W*C²)\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"TOTAL FLOPs: {total_flops:,}\")\n",
    "    print(f\"TOTAL GFLOPs: {total_flops / 1e9:.3f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Test du modèle TimesNet\n",
    "from models.TimesNet import Model as TimesNet\n",
    "import math\n",
    "\n",
    "# Configuration pour le modèle TimesNet\n",
    "conf_timesnet = {\n",
    "    'task_name': 'anomaly_detection',\n",
    "    'seq_len': 96,\n",
    "    'pred_len': 96,\n",
    "    'label_len': 10,\n",
    "    'enc_in': 10,        # Features d'entrée\n",
    "    'c_out': 10,         # Features de sortie\n",
    "    'num_class': 10,     # Nombre de classes pour classification\n",
    "    'd_model': 32,       # Dimension du modèle\n",
    "    'd_ff': 100,          # Dimension feedforward (dans Inception blocks)\n",
    "    'e_layers': 2,       # Nombre de couches TimesBlock\n",
    "    'top_k': 5,          # Nombre de périodes top-k\n",
    "    'num_kernels': 4,    # Nombre de kernels dans Inception\n",
    "    'dropout': 0.1,\n",
    "    'embed': 'timeF',\n",
    "    'freq': 'h'\n",
    "}\n",
    "configs_timesnet = type('Config', (), conf_timesnet)()\n",
    "\n",
    "# Créer le modèle TimesNet\n",
    "model_timesnet = TimesNet(configs_timesnet)\n",
    "print(\"Model parameters:\", sum(p.numel() for p in model_timesnet.parameters()))\n",
    "\n",
    "print(\"=== MODÈLE TIMESNET CRÉÉ ===\")\n",
    "print(f\"Task: {model_timesnet.task_name}\")\n",
    "print(f\"Sequence length: {model_timesnet.seq_len}\")\n",
    "if hasattr(model_timesnet, 'pred_len'):\n",
    "    print(f\"Prediction length: {model_timesnet.pred_len}\")\n",
    "print(f\"TimesBlock layers: {len(model_timesnet.model)}\")\n",
    "print(f\"Features: {conf_timesnet['enc_in']}\")\n",
    "print(f\"d_model: {conf_timesnet['d_model']}\")\n",
    "print(f\"d_ff: {conf_timesnet['d_ff']}\")\n",
    "print(f\"Top-k periods: {conf_timesnet['top_k']}\")\n",
    "\n",
    "# Test des FLOPs\n",
    "batch_size = 32\n",
    "sequence_length = 96\n",
    "\n",
    "flops_breakdown, total_flops = count_flops_timesnet(\n",
    "    model_timesnet, batch_size=batch_size, sequence_length=sequence_length, configs=conf_timesnet\n",
    ")\n",
    "\n",
    "# Afficher les résultats\n",
    "print_flops_breakdown_timesnet(flops_breakdown, total_flops)\n",
    "\n",
    "# Test avec différentes longueurs de séquence\n",
    "print(f\"\\n=== TEST AVEC DIFFÉRENTES LONGUEURS DE SÉQUENCE ===\")\n",
    "flops_timesnet = []\n",
    "\n",
    "for seq_len in SEQ_LENGTHS:\n",
    "    # Ajuster la configuration pour chaque longueur de séquence\n",
    "    conf_test = conf_timesnet.copy()\n",
    "    conf_test['seq_len'] = seq_len\n",
    "    \n",
    "    flops_breakdown, total_flops = count_flops_timesnet(\n",
    "        model_timesnet, batch_size=10, sequence_length=seq_len, configs=conf_test\n",
    "    )\n",
    "    print(f\"Sequence Length: {seq_len:4d}, Total FLOPs: {total_flops:12,}, GFLOPs: {total_flops/1e9:8.3f}\")\n",
    "    flops_timesnet.append(total_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3642c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.set(style=\"whitegrid\", font_scale=1.2, palette=\"muted\")\n",
    "\n",
    "sns.lineplot(x=SEQ_LENGTHS, y=flops_mamba, label='Mamba', linewidth=2)\n",
    "sns.lineplot(x=SEQ_LENGTHS, y=flops_transformer_vanilla, label='Transformer', linewidth=2)\n",
    "sns.lineplot(x=SEQ_LENGTHS, y=flops_reformer, label='Reformer', linewidth=2)\n",
    "sns.lineplot(x=SEQ_LENGTHS, y=flops_est, label='EST', linestyle='--', linewidth=3)\n",
    "sns.lineplot(x=SEQ_LENGTHS, y=flops_itransformer, label='iTransformer', linewidth=2)\n",
    "sns.lineplot(x=SEQ_LENGTHS, y=flops_patchtst, label='PatchTST', linewidth=2)\n",
    "sns.lineplot(x=SEQ_LENGTHS, y=flops_timesnet, label='TimesNet', linewidth=2)\n",
    "\n",
    "plt.xlabel('Sequence Length', fontsize=14, labelpad=10, weight='bold')\n",
    "plt.ylabel('FLOPs', fontsize=14, labelpad=10, weight='bold')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xticks([1, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7], ['1', '10', '100', '1K', '10K', '100K', '1M', '10M'])\n",
    "plt.title('FLOPs vs Sequence Length', fontsize=16, weight='bold', pad=25)\n",
    "plt.suptitle('~1M Parameters model size', fontsize=12, y=0.82, x=0.55)\n",
    "plt.legend(fontsize=12, title_fontsize=13, loc='upper left', frameon=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('flops.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4781d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=SEQ_LENGTHS, y=flops_reformer, label='Mamba', linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094b145d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5675fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b089eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
