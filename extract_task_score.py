import os
import re
import numpy as np
import pandas as pd
from pathlib import Path
import ast
import argparse
from typing import Dict, List, Tuple, Any

def find_log_file(log_dir: Path, prefix: str) -> Path:
    """
    Trouve le premier fichier log '.out' dans un rÃ©pertoire qui commence par un prÃ©fixe donnÃ©.
    """
    if not log_dir.is_dir():
        raise FileNotFoundError(f"Le dossier de logs '{log_dir}' n'existe pas.")
    for filename in os.listdir(log_dir):
        if filename.startswith(prefix) and filename.endswith('.out'):
            return log_dir / filename
    raise FileNotFoundError(f"Aucun fichier '.out' avec le prÃ©fixe '{prefix}' trouvÃ© dans '{log_dir}'")

def extract_anomaly_detection_results(base_dir: Path) -> List[Dict]:
    """Extrait tous les rÃ©sultats de dÃ©tection d'anomalies."""
    filename = base_dir / "result_anomaly_detection.txt"
    results = []
    
    try:
        with open(filename, 'r') as f:
            content = f.read()
        
        # Pattern pour extraire les informations de chaque tÃ¢che
        pattern = r'anomaly_detection_(\w+)_EST.*?Accuracy : ([\d.]+), Precision : ([\d.]+), Recall : ([\d.]+), F-score : ([\d.]+)'
        matches = re.findall(pattern, content, re.DOTALL)
        
        for match in matches:
            dataset, accuracy, precision, recall, f_score = match
            results.append({
                'task_type': 'anomaly_detection',
                'dataset': dataset,
                'task_name': f'anomaly_detection_{dataset}',
                'accuracy': float(accuracy),
                'precision': float(precision),
                'recall': float(recall),
                'f_score': float(f_score),
                'main_metric': float(f_score)
            })
    except FileNotFoundError:
        print(f"âš ï¸  Fichier {filename} non trouvÃ©")
    except Exception as e:
        print(f"âŒ Erreur lors de l'extraction des rÃ©sultats de dÃ©tection d'anomalies: {e}")
    
    return results

def extract_imputation_results(base_dir: Path) -> List[Dict]:
    """Extrait tous les rÃ©sultats d'imputation."""
    filename = base_dir / "result_imputation.txt"
    results = []
    
    try:
        with open(filename, 'r') as f:
            content = f.read()
        
        # Pattern pour extraire les informations de chaque tÃ¢che
        pattern = r'imputation_(\w+)_mask_([\d.]+)_EST.*?mse:([\d.]+), mae:([\d.]+)'
        matches = re.findall(pattern, content, re.DOTALL)
        
        for match in matches:
            dataset, mask_ratio, mse, mae = match
            results.append({
                'task_type': 'imputation',
                'dataset': dataset,
                'mask_ratio': float(mask_ratio),
                'task_name': f'imputation_{dataset}_mask_{mask_ratio}',
                'mse': float(mse),
                'mae': float(mae),
                'main_metric': float(mse)
            })
    except FileNotFoundError:
        print(f"âš ï¸  Fichier {filename} non trouvÃ©")
    except Exception as e:
        print(f"âŒ Erreur lors de l'extraction des rÃ©sultats d'imputation: {e}")
    
    return results

def extract_long_term_forecast_results(base_dir: Path) -> List[Dict]:
    """Extrait tous les rÃ©sultats de prÃ©vision Ã  long terme."""
    filename = base_dir / "result_long_term_forecast.txt"
    results = []
    seen_tasks = set()  # Pour Ã©viter les doublons
    
    try:
        with open(filename, 'r') as f:
            content = f.read()
        
        # Pattern plus flexible pour extraire les informations
        lines = content.strip().split('\n')
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            if line.startswith('long_term_forecast_'):
                # Extraire le nom de la tÃ¢che complet
                full_task_name = line
                
                # Extraire dataset et horizon de prÃ©diction pour crÃ©er un nom simplifiÃ©
                pattern = r'long_term_forecast_(\w+)_\d+_(\d+)_EST'
                match = re.search(pattern, full_task_name)
                
                if match and i + 1 < len(lines):
                    dataset = match.group(1)
                    horizon = int(match.group(2))
                    
                    # CrÃ©er un nom de tÃ¢che simplifiÃ© (sans les paramÃ¨tres du modÃ¨le)
                    simple_task_name = f'long_term_forecast_{dataset}_{horizon}'
                    
                    # VÃ©rifier si cette tÃ¢che a dÃ©jÃ  Ã©tÃ© traitÃ©e
                    if simple_task_name not in seen_tasks:
                        seen_tasks.add(simple_task_name)
                        
                        # Ligne suivante contient les mÃ©triques
                        metrics_line = lines[i + 1].strip()
                        mse_match = re.search(r'mse:([\d.]+)', metrics_line)
                        mae_match = re.search(r'mae:([\d.]+)', metrics_line)
                        
                        if mse_match and mae_match:
                            results.append({
                                'task_type': 'long_term_forecast',
                                'dataset': dataset,
                                'horizon': horizon,
                                'task_name': simple_task_name,
                                'full_task_name': full_task_name,  # Garder le nom complet pour rÃ©fÃ©rence
                                'mse': float(mse_match.group(1)),
                                'mae': float(mae_match.group(1)),
                                'main_metric': float(mse_match.group(1))
                            })
                    i += 2
                else:
                    i += 1
            else:
                i += 1
                
    except FileNotFoundError:
        print(f"âš ï¸  Fichier {filename} non trouvÃ©")
    except Exception as e:
        print(f"âŒ Erreur lors de l'extraction des rÃ©sultats de prÃ©vision Ã  long terme: {e}")
    
    return results

def extract_classification_results(log_dir: Path) -> List[Dict]:
    """Extrait tous les rÃ©sultats de classification."""
    results = []
    
    try:
        log_file = find_log_file(log_dir, 'classif_')
        with open(log_file, 'r') as f:
            content = f.read()
        
        # Rechercher toutes les sections de test avec un pattern plus robuste
        # Pattern pour capturer le nom de dataset dans la section de test
        test_sections = re.findall(r'>>>>>>>testing : classification_([^_<]+)_EST.*?<<<.*?accuracy:([\d.]+)', content, re.DOTALL)
        
        for dataset, accuracy in test_sections:
            # Nettoyer le nom du dataset (enlever les tirets et caractÃ¨res spÃ©ciaux si nÃ©cessaire)
            clean_dataset = dataset.replace('-', '_')
            
            results.append({
                'task_type': 'classification',
                'dataset': clean_dataset,
                'task_name': f'classification_{clean_dataset}',
                'accuracy': float(accuracy),
                'main_metric': float(accuracy)
            })
            
    except FileNotFoundError:
        print(f"âš ï¸  Fichier de log de classification non trouvÃ©")
    except Exception as e:
        print(f"âŒ Erreur lors de l'extraction des rÃ©sultats de classification: {e}")
    
    return results

def extract_short_term_forecast_results(log_dir: Path) -> List[Dict]:
    """Extrait tous les rÃ©sultats de prÃ©vision Ã  court terme."""
    results = []
    
    try:
        log_file = find_log_file(log_dir, 'short_term_forecast_')
        with open(log_file, 'r') as f:
            content = f.read()
        
        # Rechercher toutes les sections de test
        sections = re.split(r'>>>>>>>testing : (short_term_forecast_m4_\w+_EST.*?)<<<<<<<<<', content)
        
        for i in range(1, len(sections), 2):
            task_name = sections[i]
            section_content = sections[i + 1] if i + 1 < len(sections) else ""
            
            # Extraire le type de sÃ©rie temporelle (Yearly, Quarterly, Monthly, Others)
            dataset_match = re.search(r'short_term_forecast_m4_(\w+)_EST', task_name)
            if not dataset_match:
                continue
                
            dataset = dataset_match.group(1)
            
            # Chercher les mÃ©triques OWA, SMAPE, MAPE, MASE
            metrics = {}
            for metric_name in ['owa', 'smape', 'mape', 'mase']:
                pattern = f"{metric_name}: ({{.*?}})"
                match = re.search(pattern, section_content)
                if match:
                    try:
                        dict_str = match.group(1).replace("'", '"')
                        metric_dict = ast.literal_eval(dict_str)
                        metrics[metric_name] = metric_dict
                    except:
                        continue
            
            # CrÃ©er une entrÃ©e pour cette tÃ¢che
            if 'owa' in metrics:
                task_result = {
                    'task_type': 'short_term_forecast',
                    'dataset': dataset,
                    'task_name': f'short_term_forecast_m4_{dataset}',
                    'main_metric': metrics['owa'].get('Average', 0)
                }
                
                # Ajouter toutes les mÃ©triques dÃ©taillÃ©es
                for metric_name, metric_dict in metrics.items():
                    for category, value in metric_dict.items():
                        task_result[f'{metric_name}_{category.lower()}'] = value
                
                results.append(task_result)
                
    except FileNotFoundError:
        print(f"âš ï¸  Fichier de log de prÃ©vision Ã  court terme non trouvÃ©")
    except Exception as e:
        print(f"âŒ Erreur lors de l'extraction des rÃ©sultats de prÃ©vision Ã  court terme: {e}")
    
    return results

def create_detailed_results_dataframe(all_results: List[Dict]) -> pd.DataFrame:
    """CrÃ©e un DataFrame dÃ©taillÃ© avec tous les rÃ©sultats."""
    if not all_results:
        return pd.DataFrame()
    
    df = pd.DataFrame(all_results)
    
    # RÃ©organiser les colonnes pour plus de clartÃ©
    base_columns = ['task_type', 'task_name', 'dataset', 'main_metric']
    other_columns = [col for col in df.columns if col not in base_columns]
    
    return df[base_columns + sorted(other_columns)]

def save_results_to_csv(df: pd.DataFrame, run_name: str, output_dir: Path = None):
    """Sauvegarde les rÃ©sultats dans un fichier CSV."""
    if output_dir is None:
        output_dir = Path.cwd()
    
    output_file = output_dir / f"detailed_results_{run_name}.csv"
    df.to_csv(output_file, index=False)
    print(f"âœ… RÃ©sultats sauvegardÃ©s dans: {output_file}")
    return output_file

def print_summary_statistics(df: pd.DataFrame):
    """Affiche des statistiques rÃ©sumÃ©es par type de tÃ¢che."""
    print("\n" + "="*80)
    print("ğŸ“Š STATISTIQUES RÃ‰SUMÃ‰ES PAR TYPE DE TÃ‚CHE")
    print("="*80)
    
    for task_type in df['task_type'].unique():
        task_df = df[df['task_type'] == task_type]
        print(f"\nğŸ”¹ {task_type.upper().replace('_', ' ')}")
        print(f"   Nombre de tÃ¢ches: {len(task_df)}")
        print(f"   MÃ©trique principale moyenne: {task_df['main_metric'].mean():.4f}")
        print(f"   MÃ©trique principale mÃ©diane: {task_df['main_metric'].median():.4f}")
        print(f"   Ã‰cart-type: {task_df['main_metric'].std():.4f}")
        
        # Afficher quelques exemples de noms de tÃ¢ches pour vÃ©rifier
        print(f"   Exemples de tÃ¢ches:")
        for i, task_name in enumerate(task_df['task_name'].head(3)):
            print(f"     - {task_name}")
        if len(task_df) > 3:
            print(f"     ... et {len(task_df) - 3} autres")

def main():
    """
    Fonction principale qui parse les arguments et lance l'extraction dÃ©taillÃ©e.
    """
    parser = argparse.ArgumentParser(
        description="Extrait les rÃ©sultats dÃ©taillÃ©s pour toutes les tÃ¢ches individuelles."
    )
    parser.add_argument(
        "run_directory", 
        type=str, 
        help="Le nom du dossier contenant les sous-dossiers 'logs' et 'results' (ex: run_1)"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help="Dossier de sortie pour le fichier CSV (dÃ©faut: rÃ©pertoire courant)"
    )
    args = parser.parse_args()

    # Construction des chemins
    base_path = Path(args.run_directory)
    log_dir = base_path / "logs"
    results_dir = base_path
    output_dir = Path(args.output_dir) if args.output_dir else None

    # Validation des chemins
    if not base_path.is_dir():
        print(f"âŒ Erreur: Le dossier spÃ©cifiÃ© '{base_path}' n'a pas Ã©tÃ© trouvÃ©.")
        return

    print(f"ğŸ” Extraction des rÃ©sultats dÃ©taillÃ©s pour: {base_path.name}")
    print("-" * 60)

    # Extraction des rÃ©sultats pour chaque type de tÃ¢che
    all_results = []
    
    print("ğŸ“‹ Extraction des rÃ©sultats de dÃ©tection d'anomalies...")
    all_results.extend(extract_anomaly_detection_results(results_dir))
    
    print("ğŸ“‹ Extraction des rÃ©sultats d'imputation...")
    all_results.extend(extract_imputation_results(results_dir))
    
    print("ğŸ“‹ Extraction des rÃ©sultats de prÃ©vision Ã  long terme...")
    all_results.extend(extract_long_term_forecast_results(results_dir))
    
    print("ğŸ“‹ Extraction des rÃ©sultats de classification...")
    all_results.extend(extract_classification_results(log_dir))
    
    print("ğŸ“‹ Extraction des rÃ©sultats de prÃ©vision Ã  court terme...")
    all_results.extend(extract_short_term_forecast_results(log_dir))

    if not all_results:
        print("âŒ Aucun rÃ©sultat trouvÃ©!")
        return

    # CrÃ©ation du DataFrame
    print(f"\nğŸ“Š CrÃ©ation du DataFrame avec {len(all_results)} tÃ¢ches...")
    df = create_detailed_results_dataframe(all_results)
    
    # Sauvegarde en CSV
    csv_file = save_results_to_csv(df, base_path.name, output_dir)
    
    # Affichage des statistiques
    print_summary_statistics(df)
    
    # Affichage d'un aperÃ§u du DataFrame
    print("\n" + "="*80)
    print("ğŸ“‹ APERÃ‡U DES RÃ‰SULTATS (5 premiÃ¨res lignes)")
    print("="*80)
    print(df.head().to_string(index=False))
    
    print(f"\nâœ… Extraction terminÃ©e! {len(all_results)} tÃ¢ches traitÃ©es.")
    print(f"ğŸ“ Fichier CSV gÃ©nÃ©rÃ©: {csv_file}")

if __name__ == "__main__":
    main()